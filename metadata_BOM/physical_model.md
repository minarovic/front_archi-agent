# TierIndex ‚Äì fyzick√Ω model (Delta Lake)

**Audience:** üìä Data Architect, üë®‚Äçüíª Developer  
**Priority:** üî¥ Critical - core architecture  
**Last updated:** 2025-10-04  
**Related docs:** [TierIndex slovn√≠k pojm≈Ø](./tierindex_slovnik_pojmu.md), [SLA](./SLA.md), [Governance](./governance_lineage.md), [ER diagram](./er_diagram.md)

---

## Kontext
- Navazuje na logick√Ω ERD (`scrum/architecture/er_diagram.md`) a dr≈æ√≠ stejn√© mantinely (TierIndex-first, runtime mimo Databricks).
- Databricks slou≈æ√≠ jako datov√° platforma: **Bronze** = raw ingest (DAP standard), **Silver** = normalizovan√© tabulky baseline/changeset, **Gold** = metriky a view pro API.
- Dokument je p≈ô√≠prava pro prezentaci architektovi/DAP ‚Äì zamƒõ≈ôujeme se na p≈ôehled a vizualizace, skripty dopln√≠me pozdƒõji.

---

## Bronze vrstva ‚Äì raw ingest (DAP standard)

**√öƒçel:** Zachov√°n√≠ p≈Øvodn√≠ch dat bez transformac√≠. Odpov√≠d√° DAP "Integration" f√°zi (viz `dap_docs/SKDAP-DAPArchitectureDetails-280925-2209-102.pdf`): _"Goal of the integration step is to transfer data from the original location to the central data storage in it's original format; without any transformations."_

### Ingest mechanismus
Podle DAP dokumentace existuje nƒõkolik standardn√≠ch p≈ô√≠stup≈Ø:
- **Cloud services:** Azure Data Factory, Event Hub
- **OP services:** Kafka streaming, SAP Data Services, Offloader
- **Typy:** Static data (db-based, file extracts), Streaming data (real-time), API-based approach (remote web services)

**N√°≈° p≈ô√≠stup:** API-based ‚Äì periodick√Ω batch ingest z DnB Direct+ a Sayari API p≈ôes Python/Databricks job.

### Bronze tabulky

#### `bronze.dnb_raw`
Surov√© odpovƒõdi z DnB API (FamilyTreeFull, CMPBOL).
- **Schema:** `request_id STRING`, `endpoint STRING`, `duns STRING`, `response_payload STRING` (JSON blob), `http_status INT`, `ingested_at TIMESTAMP`, `source_batch_id STRING`
- **Partitioning:** `PARTITIONED BY (endpoint, date(ingested_at))`
- **Retention:** 90 dn√≠ (audit trail)

#### `bronze.sayari_raw`
Surov√© odpovƒõdi ze Sayari API (entity search, relationships, UBO).
- **Schema:** `request_id STRING`, `endpoint STRING`, `entity_id STRING`, `response_payload STRING` (JSON blob), `http_status INT`, `ingested_at TIMESTAMP`, `source_batch_id STRING`
- **Partitioning:** `PARTITIONED BY (endpoint, date(ingested_at))`
- **Retention:** 90 dn√≠ (audit trail)

### Ingest job
**Notebook/job:** `notebooks/ti_ingest_sources.py`
**Frekvence:** 1√ó dennƒõ (02:00 UTC)
**Logika:**
1. Naƒçti seznam DUNS/entit k aktualizaci (z watch listu nebo Tier1 baseline)
2. Pro ka≈ædou entitu: volej DnB + Sayari API endpoints
3. Zapi≈° surov√© odpovƒõdi do `bronze.*_raw` tabulek (append mode)
4. Zaloguj `batch_id` + timestamp pro lineage tracking
5. V p≈ô√≠padƒõ chyby: retry 3√ó, pak DLQ (dead letter queue)

**Monitoring:** Azure Monitor + Databricks job metrics (success rate, latency, error count)

### Governance Bronze vrstvy
- **P≈ô√≠stup:** Read-only pro silver ETL job; write pouze p≈ôes ingest job.
- **Lineage:** Unity Catalog automatick√° lineage (bronze ‚Üí silver).
- **Data Quality:** Validace HTTP status 200, JSON parse check; nevalidn√≠ z√°znamy do `bronze.errors` tabulky.

---

## Silver vrstva ‚Äì normalizovan√© tabulky
- **`silver.ti_entity_s`** ‚Äì aktu√°ln√≠ stav entit v baseline (partition `snapshot_date`, Z-ORDER `entity_id`).
- **`silver.ti_edge_s`** ‚Äì hrany mezi entitami (partition `snapshot_date`, Z-ORDER `source_entity_id`, `target_entity_id`).
- **`silver.ti_tier_assignment_s`** ‚Äì p≈ôi≈ôazen√≠ tier≈Ø k root≈Øm (partition `snapshot_date`).
- **Changesety**: `silver.ti_changeset_entity`, `silver.ti_changeset_edge`, `silver.ti_changeset_tier` (`change_date` partition, atribut `change_type`).

## Gold vrstva ‚Äì konzumace API
- **`gold.ti_manifest`** ‚Äì auditovan√Ω seznam publikovan√Ωch kombinac√≠ baseline + changeset≈Ø.
- **`gold.ti_metrics`** ‚Äì metriky a agreg√°ty pro frontend/chat (cluster na `scope_entity_id`).
- **`gold.vw_entity_graph`** ‚Äì view s nested edges/tiers pro rychl√© ƒçten√≠ API (kontrakt pro SLA < 200 ms).

## Governance a provoz
- **Pr√°va**: role `ntier_reader` (read-only gold), `ntier_admin` (spr√°va silver/gold + manifest).
- **√ödr≈æba**: t√Ωdenn√≠ `OPTIMIZE ... ZORDER BY (entity_id)` pro silver, `VACUUM RETAIN 7 DAYS`.
- **Lineage**: automaticky p≈ôes Unity Catalog; manifest v≈ædy odkazuje na verzi baseline a seznam changeset≈Ø.
- **Fallback**: posledn√≠ manifest + export gold tabulek ulo≈æen√Ω mimo Databricks (degraded mode).

## Naming a konvence
- Katalogy: `skoda_tierindex_dev`, `skoda_tierindex_test`, `skoda_tierindex_prod`.
- Sch√©mata: `silver` (normalizovan√© tabulky), `gold` (metriky + view), `governance` (manifest).
- Prefixy tabulek: `ti_` pro hlavn√≠ entity, `ti_changeset_` pro inkrementy, `vw_` pro view.
- Sloupce auditn√≠ stopy: `snapshot_version`, `snapshot_date`, `changeset_id`, `published_at`.

## API kontrakt
- API ƒçte v√Ωhradnƒõ `gold.vw_entity_graph` a `gold.ti_metrics`; zmƒõny jsou p≈ôid√°van√© jako nov√© sloupce/fields.
- Backward kompatibilitu dr≈æ√≠me p≈ôes v√Ωchoz√≠ hodnoty a verzi manifestu (hlaviƒçka odpovƒõdi).
- Deaktivace metrik prob√≠h√° oznaƒçen√≠m `is_deprecated = true` a odstranƒõn√≠m a≈æ po dvou release cyklech.
- Frontend vyu≈æ√≠v√° caching; SLA/RPO/RTO viz `scrum/architecture/SLA.md`.

## Navrhovan√© skripty / notebooky (po schv√°len√≠ modelu)
| Artefakt                          | Typ                      | Hlavn√≠ √∫loha                                                               | Trigger / pl√°n                |
| --------------------------------- | ------------------------ | -------------------------------------------------------------------------- | ----------------------------- |
| `notebooks/ti_ingest_sources`     | Notebook (PySpark)       | St√°hne Sayari/DnB d√°vku, ulo≈æ√≠ do bronze/silver staging                    | Databricks Workflow 02:00 CET |
| `jobs/ti_build_baseline.py`       | Job skript               | Normalizace do `silver.ti_*_s`, verze snapshotu, checksumy                 | Po ingestu, dennƒõ             |
| `jobs/ti_apply_changeset.py`      | Job skript               | Z√°pis changesetu a `MERGE` do silver baseline, p≈ô√≠prava QA datasetu        | Ka≈æd√° hodina / on-demand      |
| `notebooks/ti_validate_publish`   | Notebook (SQL + PySpark) | QA testy (poƒçty, checksumy, smoke metriky) a publish do `gold.ti_manifest` | Spou≈°t√≠ orchestr√°tor po MERGE |
| `sql/gold_metrics_refresh.sql`    | SQL skript               | Rebuild `gold.ti_metrics`, aktualizace `vw_entity_graph`                   | Trigger z manifestu           |
| `scripts/export_gold_snapshot.py` | Python CLI               | Export posledn√≠ho manifestu + gold tabulek pro fallback cache              | Po √∫spƒõ≈°n√©m manifestu         |

## Mermaid ‚Äì p≈ôehled tabulek
```mermaid
classDiagram
    class Silver_Entity {
        snapshot_date : DATE
        snapshot_version : STRING
        entity_id : STRING
        entity_type : STRING
        name : STRING
        country : STRING
        source_system : STRING
    }
    class Silver_Edge {
        snapshot_date : DATE
        edge_id : STRING
        source_entity_id : STRING
        target_entity_id : STRING
        rel_type : STRING
        direction : STRING
    }
    class Silver_Tier {
        snapshot_date : DATE
        tier_assignment_id : STRING
        root_entity_id : STRING
        tier_level : STRING
        effective_from : DATE
    }
    class Changeset_Entity {
        change_date : DATE
        changeset_id : STRING
        change_type : STRING
        entity_id : STRING
        payload : STRUCT
    }
    class Changeset_Edge {
        change_date : DATE
        changeset_id : STRING
        edge_id : STRING
        change_type : STRING
    }
    class Changeset_Tier {
        change_date : DATE
        changeset_id : STRING
        tier_assignment_id : STRING
        change_type : STRING
    }
    class Gold_Manifest {
        manifest_id : STRING
        published_at : TIMESTAMP
        baseline_version : STRING
        applied_changesets : ARRAY<STRING>
        checksum : STRING
    }
    class Gold_Metrics {
        metric_id : STRING
        metric_name : STRING
        scope_entity_id : STRING
        metric_value : DECIMAL
        refreshed_at : TIMESTAMP
    }
    class Gold_View {
        entity_id : STRING
        name : STRING
        country : STRING
        tiers : ARRAY
        edges : ARRAY
    }

    Silver_Entity --> Silver_Edge : source
    Silver_Entity --> Silver_Tier : assigned
    Changeset_Entity --> Silver_Entity : merge
    Changeset_Edge --> Silver_Edge : merge
    Changeset_Tier --> Silver_Tier : merge
    Gold_Manifest --> Gold_Metrics : publishes
    Gold_Manifest --> Gold_View : publishes
```

## Dal≈°√≠ kroky pro prezentaci
- P≈ôipravit uk√°zkov√© SQL dotazy/dashboard snapshoty pro gold view a metriky.
- Doplnit checklist QA do `scrum/architecture/governance_lineage.md` o detailn√≠ validation testy.
- Odsouhlasit SLA hodnoty s DAP a prom√≠tnout je do Unity Catalogu.
