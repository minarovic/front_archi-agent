# Tool 0 - Business Request Parser - Detailn√≠ Dokumentace

**√öƒçel:** Parsuje standardizovan√© Markdown business dokumenty a extrahuje strukturovan√Ω kontext pro downstream tools.

**Pattern:** Direct OpenAI SDK with Azure endpoint + JSON mode (Pattern A)

---

## Architektura

```mermaid
flowchart LR
    INPUT[business_request.md] --> LOAD[Load Document]
    LOAD --> LLM[LLM Parser<br/>OpenAI SDK<br/>test-gpt-5-mini]
    LLM --> SCHEMA[Pydantic Schema<br/>BusinessRequest]
    SCHEMA --> OUTPUT[business_context.json]

    style LLM fill:#ffccbc,color:#000,stroke:#333,stroke-width:2px
    style SCHEMA fill:#c5cae9,color:#000,stroke:#333,stroke-width:2px
    style LOAD fill:#c8e6c9,color:#000,stroke:#333,stroke-width:2px
    style INPUT fill:#e1f5fe,color:#000,stroke:#333,stroke-width:2px
    style OUTPUT fill:#fff9c4,color:#000,stroke:#333,stroke-width:2px
```

**Legenda:**
- üîµ **Modr√°** (INPUT): Vstupn√≠ Markdown dokument
- üü¢ **Zelen√°** (LOAD): Deterministick√Ω load operace
- üü† **Oran≈æov√°** (LLM): OpenAI SDK s Azure endpoint
- üü£ **Fialov√°** (SCHEMA): Pydantic validace
- üü° **≈Ωlut√°** (OUTPUT): JSON output

---

## Input Schema (Markdown Template)

Tool 0 oƒçek√°v√° standardizovan√Ω Markdown form√°t:

```markdown
# Po≈æadavek na datov√Ω projekt

**Metadata:**
- Projekt: Anal√Ωza n√°kupu
- Zadavatel: Jan Nov√°k
- Datum: 2025-11-01

## C√≠l projektu
Analyzovat n√°kupn√≠ objedn√°vky za Q3 2025 pro optimalizaci
dodavatelsk√©ho portfolia a identifikaci √∫spor.

## Rozsah (Scope In)
- BS N√°kup (dm_bs_purchase)
- Dodavatel√©, objedn√°vky, polo≈æky objedn√°vek
- Data za Q3 2025

## Mimo rozsah (Scope Out)
- HR data
- Real-time monitoring
- Finance modul

## Kl√≠ƒçov√© entity
- Dodavatel√© (Suppliers)
- N√°kupn√≠ objedn√°vky (Purchase Orders)
- Materi√°ly (Materials)

## Po≈æadovan√© metriky
- Objem objedn√°vek (order_quantity)
- Hodnota objedn√°vek (order_value)
- Doba dod√°n√≠ (delivery_time)

## Zdroje dat
- SAP ERP
- Databricks Unity Catalog (dm_bs_purchase)

## Omezen√≠
- Pouze Q3 2025
- Bez PII dat (osobn√≠ √∫daje)
- GDPR compliance

## Oƒçek√°van√© dod√°vky
- Power BI dashboard
- SQL skripty pro anal√Ωzu
- Dokumentace datov√©ho modelu
```

---

## Output Schema (Pydantic)

```python
from pydantic import BaseModel, Field

class ProjectMetadata(BaseModel):
    """Metadata business po≈æadavku."""
    project_name: str = Field(description="N√°zev projektu")
    sponsor: str = Field(description="Zadavatel projektu")
    submitted_at: str = Field(description="Datum pod√°n√≠ v ISO 8601 form√°tu")
    extra: dict = Field(default_factory=dict, description="Dal≈°√≠ metadata")

class BusinessRequest(BaseModel):
    """Kompletn√≠ parsovan√Ω business po≈æadavek."""
    project_metadata: ProjectMetadata
    goal: str = Field(description="Hlavn√≠ c√≠l projektu")
    scope_in: str = Field(description="Co je souƒç√°st√≠ rozsahu")
    scope_out: str = Field(description="Co nen√≠ souƒç√°st√≠ rozsahu")
    entities: list[str] = Field(
        default_factory=list,
        description="Kl√≠ƒçov√© business entity (nap≈ô. Suppliers, Orders)"
    )
    metrics: list[str] = Field(
        default_factory=list,
        description="Po≈æadovan√© metriky a KPIs"
    )
    sources: list[str] = Field(
        default_factory=list,
        description="Oƒçek√°van√© datov√© zdroje (SAP, Databricks, atd.)"
    )
    constraints: list[str] = Field(
        default_factory=list,
        description="Omezen√≠ projektu (ƒçasov√°, technick√°, pr√°vn√≠)"
    )
    deliverables: list[str] = Field(
        default_factory=list,
        description="Oƒçek√°van√© dod√°vky projektu"
    )
```

---

## Output Example

```json
{
  "project_metadata": {
    "project_name": "Anal√Ωza n√°kupu Q3 2025",
    "sponsor": "Jan Nov√°k",
    "submitted_at": "2025-11-01T00:00:00Z",
    "extra": {}
  },
  "goal": "Analyzovat n√°kupn√≠ objedn√°vky za Q3 2025 pro optimalizaci dodavatelsk√©ho portfolia a identifikaci √∫spor",
  "scope_in": "BS N√°kup (dm_bs_purchase), Dodavatel√©, Objedn√°vky, Polo≈æky objedn√°vek, Data za Q3 2025",
  "scope_out": "HR data, Real-time monitoring, Finance modul",
  "entities": [
    "Suppliers",
    "Purchase Orders",
    "Materials"
  ],
  "metrics": [
    "order_quantity",
    "order_value",
    "delivery_time"
  ],
  "sources": [
    "SAP ERP",
    "Databricks Unity Catalog (dm_bs_purchase)"
  ],
  "constraints": [
    "Pouze Q3 2025",
    "Bez PII dat",
    "GDPR compliance"
  ],
  "deliverables": [
    "Power BI dashboard",
    "SQL skripty pro anal√Ωzu",
    "Dokumentace datov√©ho modelu"
  ]
}
```

---

## Implementation Pattern (Pattern A)

Tool 0 pou≈æ√≠v√° **p≈ô√≠m√Ω OpenAI SDK** s Azure endpointem, **ne LangChain agents**.

### Azure Configuration

```python
import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# Azure OpenAI konfigurace
AZURE_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")  # test-gpt-5-mini

client = OpenAI(
    base_url=AZURE_ENDPOINT,
    api_key=AZURE_API_KEY
)
```

### Parsing Logic

```python
from pydantic import ValidationError
import json

def parse_business_request(markdown_text: str) -> tuple[dict, str, str]:
    """
    Parsuje Markdown business dokument pomoc√≠ Azure OpenAI.

    Args:
        markdown_text: Obsah Markdown dokumentu

    Returns:
        tuple: (parsed_json, raw_response, prompt_used)
    """

    # System prompt
    system_prompt = """Jsi expert na anal√Ωzu business po≈æadavk≈Ø.
Tv√Ωm √∫kolem je extrahovat strukturovan√° data z Markdown dokumentu.

PRAVIDLA:
- Extrahuj v≈°echny sekce podle vzoru
- Zachovej p≈Øvodn√≠ form√°t a jazyk (ƒçe≈°tina/angliƒçtina)
- Pro chybƒõj√≠c√≠ sekce vra≈• "unknown" nebo pr√°zdn√© pole []
- Datum p≈ôeveƒè do ISO 8601 (YYYY-MM-DDTHH:MM:SSZ)
- Entities: seznam kl√≠ƒçov√Ωch business entit (Suppliers, Orders, atd.)
- Metrics: seznam mƒõ≈ôiteln√Ωch metrik (order_value, delivery_time, atd.)
- Sources: seznam datov√Ωch zdroj≈Ø (SAP, Databricks, atd.)
- Constraints: seznam omezen√≠ (ƒçasov√°, technick√°, pr√°vn√≠)
- Deliverables: seznam oƒçek√°van√Ωch dod√°vek
"""

    # User message
    user_message = f"""Analyzuj tento business po≈æadavek a extrahuj strukturovan√° data:

{markdown_text}

Vra≈• v√Ωsledek jako validn√≠ JSON objekt podle p≈ôedepsan√©ho sch√©matu."""

    # LLM call s JSON mode
    response = client.chat.completions.create(
        model=DEPLOYMENT_NAME,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ],
        response_format={"type": "json_object"},  # JSON mode
        temperature=1.0  # default pro gpt-5-mini (nelze zmƒõnit)
    )

    raw_response = response.choices[0].message.content

    # Parse JSON
    parsed_json = json.loads(raw_response)

    # Pydantic validace
    try:
        validated = BusinessRequest(**parsed_json)
        return (validated.model_dump(), raw_response, system_prompt + "\n\n" + user_message)
    except ValidationError as e:
        raise ValueError(f"Pydantic validation failed: {e}")
```

---

## Key Features

- ‚úÖ **Simple architecture:** Jedin√Ω LLM call bez slo≈æit√Ωch agent workflows
- ‚úÖ **JSON mode:** Garantovan√© JSON strukturovan√© v√Ωstupy
- ‚úÖ **Pydantic validation:** Striktn√≠ kontrola sch√©matu po LLM odpovƒõdi
- ‚úÖ **Czech/English support:** Multilingv√°ln√≠ podpora (zachov√°v√° p≈Øvodn√≠ jazyk)
- ‚úÖ **Fallback logic:** `default_factory=list` pro chybƒõj√≠c√≠ sekce
- ‚úÖ **ISO 8601 dates:** Standardizovan√© datum form√°ty
- ‚úÖ **Return tuple:** Vrac√≠ (parsed_json, raw_response, prompt) pro audit trail

---

## Timing

- **Average execution:** ~3-5s (depends on document length)
- **Target:** <10s ‚úÖ
- **Breakdown:**
  - Document load: <1s
  - LLM parsing: 2-4s (Azure Sweden Central)
  - Pydantic validation: <1s

---

## Sample Files

**Input samples:** `data/tool0_samples/business_request_*.md`
**Output samples:** `data/tool0_samples/YYYY-MM-DDTHH:MM:SS.*_parsed.json`

---

## Testing

**Demo notebook:** `notebooks/tool0_parser_demo.ipynb`
**Test script:** `test_azure_model.py`

---

## Known Limitations

- ‚ö†Ô∏è **Temperature fixed:** gpt-5-mini doesn't support temperature parameter (always 1.0)
- ‚ö†Ô∏è **No streaming:** Pattern A uses synchronous calls only
- ‚ö†Ô∏è **Manual validation:** Pydantic validation happens post-LLM (not during generation)
- ‚ö†Ô∏è **Section detection:** Relies on Markdown headers (case-sensitive)

---

## Future Enhancements (Post-MVP)

- üîÆ Add streaming support for large documents
- üîÆ Implement confidence scoring per field
- üîÆ Add automatic language detection
- üîÆ Support alternative input formats (Word, PDF)
- üîÆ Add validation against Collibra taxonomy

---

**N√°vrat na hlavn√≠ dokumentaci:** [mcop-architecture.md](./mcop-architecture.md#3-tool-0---business-request-parser)
