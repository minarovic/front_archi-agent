# MCOP - Metadata Copilot Project Instructions

## Project Context

**Name:** Metadata Copilot (MCOP)
**Purpose:** LangGraph-based agent connecting business requirements with technical metadata (Collibra, Databricks Unity Catalog, SAP)
**Current Phase:** MVP Deployment (Tool 0-3 on Databricks)
**Team:** MetaWizards Data Engineering

---

## Azure OpenAI Configuration

### Endpoint Format (IMPORTANT!)
- **CORRECT Endpoint:** Both `.cognitiveservices.azure.com` AND `.openai.azure.com` are VALID per Azure documentation
- **Current Endpoint:** `https://minar-mhi2wuzy-swedencentral.cognitiveservices.azure.com/openai/v1/`
- **Status:** ‚úÖ Fully functional with OpenAI Python SDK v1.x
- **DO NOT warn** about `.cognitiveservices.azure.com` being incompatible - it is officially supported by Azure

### Azure AI Foundry Setup
```python
# Pattern A: Direct OpenAI SDK (Tool 0)
from openai import OpenAI
client = OpenAI(
    base_url="https://minar-mhi2wuzy-swedencentral.cognitiveservices.azure.com/openai/v1/",
    api_key=AZURE_API_KEY
)

# Pattern B: Azure OpenAI SDK (Tool 1-3)
from openai import AzureOpenAI
client = AzureOpenAI(
    api_version="2024-12-01-preview",
    azure_endpoint="https://minar-mhi2wuzy-swedencentral.cognitiveservices.azure.com/",
    api_key=AZURE_API_KEY
)
```

**Model:** gpt-5-mini-2025-08-07
**Deployment:** test-gpt-5-mini
**Region:** Sweden Central

---

## Databricks Environment

### Secrets Configuration
- **Scope:** `mcop`
- **Keys:**
  - `azure-openai-endpoint`
  - `azure-openai-api-key`
  - `azure-openai-deployment-name`

### Access Secrets
```python
AZURE_ENDPOINT = dbutils.secrets.get(scope="mcop", key="azure-openai-endpoint")
AZURE_API_KEY = dbutils.secrets.get(scope="mcop", key="azure-openai-api-key")
DEPLOYMENT_NAME = dbutils.secrets.get(scope="mcop", key="azure-openai-deployment-name")
```

### DBFS Paths
```
dbfs:/FileStore/mcop/
‚îú‚îÄ‚îÄ metadata/BA-BS_Datamarts_metadata.json
‚îú‚îÄ‚îÄ tool0_samples/
‚îú‚îÄ‚îÄ tool1/
‚îú‚îÄ‚îÄ tool2/
‚îî‚îÄ‚îÄ tool3/
```

### Workspace Structure
```
/Workspace/Users/minarovic@metawizards.com/mcop/
‚îú‚îÄ‚îÄ tool0_parser_databricks
‚îú‚îÄ‚îÄ tool1_ingest_databricks
‚îú‚îÄ‚îÄ tool2_structure_databricks
‚îî‚îÄ‚îÄ tool3_quality_databricks
```

---

## Tool Pipeline Architecture

### Tool 0: Business Request Parser
- **Pattern:** Direct OpenAI SDK with JSON mode
- **Input:** Markdown business document (Czech/English mix)
- **Output:** Structured JSON (ProjectMetadata, entities, metrics, sources, constraints, deliverables)
- **Validation:** Pydantic `BusinessRequest` model
- **Save to:** `/dbfs/FileStore/mcop/tool0_samples/YYYY-MM-DDTHH-MM-SS.json`

### Tool 1: Entity-to-Candidate Mapping
- **Pattern:** Pydantic AI + Pydantic Graph (5 nodes)
- **Nodes:** Load ‚Üí Prepare ‚Üí Mapping Agent ‚Üí Filter Agent ‚Üí Save
- **LLM Calls:** 2 agents (Mapping + Filter)
- **State Persistence:** `/dbfs/FileStore/mcop/tool1/graph_state/tool1_state.json`
- **Output:** `/dbfs/FileStore/mcop/tool1/filtered_dataset_graph.json`

### Tool 2: Structure Classification
- **Pattern:** Pydantic AI (single agent) + deterministic FK detection
- **Classification:** FACT vs DIMENSION
- **Dependencies:** Tool 0 output + Tool 1 output + metadata
- **Output:** `/dbfs/FileStore/mcop/tool2/structure_graph.json`

### Tool 3: Quality Validation
- **Pattern:** Hybrid (deterministic scoring + LLM enhancement with fallback)
- **Articulation Score:** 0-100 (description +20, owner +20, lineage +15, source_mapping +15, dq_rules +10, governance_tags +10, last_updated +10)
- **LLM Enhancement:** Risk assessment, P0-P2 recommendations, anomaly detection
- **Fallback:** Generic recommendations if LLM timeout/error
- **Output:** `/dbfs/FileStore/mcop/tool3/quality_report_graph.json`

---

## Pydantic AI vs Pydantic Graph

### When to Use What
- **Pydantic AI (Agent):** Single LLM call, structured output, simple workflows
- **Pydantic Graph:** Multi-agent orchestration, state persistence, complex branching

### Current Implementation
- **Tool 0:** ‚úÖ Pydantic AI only (no graph needed)
- **Tool 1:** ‚úÖ Pydantic Graph (2 LLM agents, checkpoint benefit)
- **Tool 2:** ‚ö†Ô∏è Pydantic Graph (refactoring to simplified multi-agent planned)
- **Tool 3:** ‚ö†Ô∏è Pydantic Graph (refactoring to simplified hybrid function planned)

### Refactoring Decision (2025-11-09)
Per analysis in `docs_langgraph/pydantic_analysis/graph_vs_multiagent_mcop.md`:
- **Keep Graph:** Tool 1 only (multi-agent + state persistence justified)
- **Simplify:** Tool 2, Tool 3 (line√°rn√≠ flow, graph overhead unnecessary)
- **Future:** Orchestrator (Tool 0‚Üí1‚Üí2‚Üí3) will use Graph for conditional branching

---

## Code Conventions

### Pydantic Models
- **Always include Field descriptions:**
  ```python
  from pydantic import BaseModel, Field

  class Entity(BaseModel):
      """Entity metadata."""
      name: str = Field(description="Entity name")
      type: str = Field(description="Entity type: FACT or DIMENSION")
  ```

### Date Handling
- **ISO 8601 format:** `YYYY-MM-DD` for dates, `YYYY-MM-DDTHH:MM:SS` for timestamps
- **JSON serialization:** Use `.isoformat()` for datetime objects
- **DBFS-safe filenames:** Replace `:` with `-` in timestamps

### Error Handling
- **No bare try/except:** Always log errors
- **Fallback strategies:** Provide generic defaults when LLM fails
- **User-friendly messages:** Explain what went wrong and how to fix

### Package Versions
```python
%pip install openai==1.30.1 pydantic==2.8.2 python-dotenv==1.0.1 mlflow==2.12.1
dbutils.library.restartPython()
```

---

## Common Patterns

### Load Tool Output
```python
from pathlib import Path
import json

# Find latest Tool 0 output
tool0_dir = Path("/dbfs/FileStore/mcop/tool0_samples")
latest_tool0 = max(tool0_dir.glob("*.json"), key=lambda p: p.stat().st_mtime)
with open(latest_tool0) as f:
    business_request = json.load(f)
```

### Save Results
```python
from datetime import datetime
from pathlib import Path
import json

timestamp = datetime.now().isoformat().replace(':', '-')
output_dir = Path('/dbfs/FileStore/mcop/tool1')
output_dir.mkdir(parents=True, exist_ok=True)

output_path = output_dir / f"{timestamp}.json"
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(result, f, indent=2, ensure_ascii=False)
```

### Pydantic AI Agent
```python
from pydantic_ai import Agent
from pydantic import BaseModel, Field

class MyOutput(BaseModel):
    """Output schema."""
    field: str = Field(description="Field description")

agent = Agent(
    "openai:test-gpt-5-mini",  # Use deployment name
    output_type=MyOutput,
    system_prompt="Your task description"
)

result = await agent.run("User input")
validated_output = result.output  # Already a Pydantic model
```

---

## Troubleshooting

### Secrets Not Found
```python
# Verify secrets exist
databricks secrets list-secrets mcop

# Verify values (CLI)
databricks secrets get mcop azure-openai-endpoint

# Test in notebook
endpoint = dbutils.secrets.get(scope="mcop", key="azure-openai-endpoint")
print(f"Endpoint length: {len(endpoint)} chars")
print(f"Endpoint ends with: ...{endpoint[-20:]}")
```

### Kernel Restart Clears Variables
```python
# Re-load secrets after dbutils.library.restartPython()
AZURE_ENDPOINT = dbutils.secrets.get(scope="mcop", key="azure-openai-endpoint").strip()
AZURE_API_KEY = dbutils.secrets.get(scope="mcop", key="azure-openai-api-key").strip()
DEPLOYMENT_NAME = dbutils.secrets.get(scope="mcop", key="azure-openai-deployment-name").strip()
```

### File Not Found in DBFS
```python
# List files
dbutils.fs.ls("dbfs:/FileStore/mcop/metadata/")

# Verify file exists
from pathlib import Path
metadata_path = Path("/dbfs/FileStore/mcop/metadata/BA-BS_Datamarts_metadata.json")
print(f"File exists: {metadata_path.exists()}")
```

---

## Documentation References

**Local Files:**
- `docs_langgraph/mcop-architecture.md` - Overall architecture
- `docs_langgraph/tool3-detailed-flow.md` - Tool 3 hybrid pipeline
- `docs_langgraph/pydantic_analysis/graph_vs_multiagent_mcop.md` - Graph vs Multi-Agent analysis
- `.github/copilot-instructions.md` - GitHub Copilot instructions
- `AGENTS.md` - AI agent guidelines

**External:**
- Azure OpenAI: https://learn.microsoft.com/azure/ai-services/openai/quickstart
- Pydantic AI: https://ai.pydantic.dev/
- Pydantic Graph: https://ai.pydantic.dev/graph/

---

## Response Guidelines

### When Suggesting Code
1. **Use correct Azure endpoint format** (both `.cognitiveservices.azure.com` and `.openai.azure.com` are valid)
2. **Include Pydantic Field descriptions** (required for all models)
3. **Use DBFS paths** (not local `data/` directories)
4. **Include error handling** (no bare try/except)
5. **Add type hints** (Python 3.13+ features encouraged)

### When Debugging
1. **Check secrets first** (most common issue after kernel restart)
2. **Verify DBFS paths** (use `/dbfs/FileStore/` prefix for Python, `dbfs:/FileStore/` for CLI)
3. **Test LLM connectivity** (simple completion call before complex agent)
4. **Validate Pydantic models** (use `.model_validate()` for explicit checking)

### When Refactoring
1. **Preserve functionality** (no breaking changes without explicit approval)
2. **Simplify when possible** (remove graph overhead if not needed)
3. **Document rationale** (explain why change is beneficial)
4. **Keep backward compatibility** (old notebooks should still work)

---

## Project Status (2025-11-09)

### Completed
- ‚úÖ Tool 0 deployed to Databricks (Pattern A: OpenAI SDK + JSON mode)
- ‚úÖ Tool 1-3 deployed to Databricks (Pattern C: Pydantic AI + Pydantic Graph)
- ‚úÖ Secrets configuration (mcop scope with 3 keys)
- ‚úÖ DBFS directory structure created
- ‚úÖ BA-BS metadata uploaded to DBFS
- ‚úÖ Graph vs Multi-Agent analysis completed

### In Progress
- ‚è≥ Tool 0 execution testing (secrets verified, ready to run)
- ‚è≥ Refactoring Tool 2 & 3 to simplified multi-agent (planned)

### Planned (Phase 2)
- üìÖ Orchestrator (Tool 0‚Üí1‚Üí2‚Üí3 pipeline with Pydantic Graph)
- üìÖ Tool 4-6 (Security Analyzer, ER Diagram, Script Generator)
- üìÖ Observability (Logfire integration)
- üìÖ Production deployment (Delta Lake, Workflows, Unity Catalog)

---

**Last Updated:** 2025-11-09
**Team Contact:** minarovic@metawizards.com
**Workspace:** https://adb-XXXX.azuredatabricks.net (Sweden Central)
