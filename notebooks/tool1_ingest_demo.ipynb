{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b434f28",
   "metadata": {},
   "source": [
    "# Tool 1 - Data Ingest Demo (LangGraph Nodes)\n",
    "\n",
    "**Purpose:** Map business entities from Tool 0 to BS metadata candidates using LangGraph agent with nodes.\n",
    "\n",
    "**LangGraph Features Tested:**\n",
    "- âœ… Agent with discrete nodes (LangGraph way of thinking)\n",
    "- âœ… **Multiple LLM nodes** (prepare = ranking, mapping = matching)\n",
    "- âœ… Shared state between nodes\n",
    "- âœ… Structured output (ToolStrategy) in multiple contexts\n",
    "- âœ… Dynamic prompt middleware (inject scope_out)\n",
    "- âœ… Streaming progress between nodes\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Load Node â†’ Prepare Node (LLM) â†’ Mapping Node (LLM) â†’ Filter Node â†’ Save Node\n",
    "     â†“            â†“                     â†“                  â†“           â†“\n",
    " Tool 0 JSON  LLM Ranking         LLM Matching        Blacklist    Results\n",
    " + BS export  (relevance)       (confidence+rationale) (deterministic) (JSON)\n",
    "```\n",
    "\n",
    "**Model:** openai:gpt-5-mini (consistent across all nodes)\n",
    "\n",
    "**Showcase:** Two intelligent LLM nodes with different purposes - demonstrates \"each node does one thing well\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52117387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# !pip install langgraph langchain langchain-openai pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b2e0f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports successful\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Annotated\n",
    "import json\n",
    "\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import dynamic_prompt\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "print(\"âœ… Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e49122",
   "metadata": {},
   "source": [
    "## 1. Define Schemas & State\n",
    "\n",
    "Pydantic schemas for structured output + LangGraph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eb0237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Schemas & state defined\n"
     ]
    }
   ],
   "source": [
    "# Pydantic schemas for structured output\n",
    "class EntityMapping(BaseModel):\n",
    "    \"\"\"Single entity mapped to a BS candidate.\"\"\"\n",
    "\n",
    "    entity: str = Field(description=\"Original entity name from Tool 0\")\n",
    "    candidate_id: str = Field(description=\"BS candidate identifier (e.g., 'dm_bs_suppliers')\")\n",
    "    candidate_name: str = Field(description=\"Human-readable candidate name\")\n",
    "    confidence: float = Field(\n",
    "        description=\"Confidence score 0.0-1.0\",\n",
    "        ge=0.0,\n",
    "        le=1.0\n",
    "    )\n",
    "    rationale: str = Field(description=\"Why this mapping was suggested\")\n",
    "\n",
    "\n",
    "class MappingSuggestions(BaseModel):\n",
    "    \"\"\"Complete set of entity mappings.\"\"\"\n",
    "\n",
    "    mappings: list[EntityMapping] = Field(\n",
    "        description=\"List of entity-to-candidate mappings\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LangGraph state (shared across all nodes)\n",
    "class Tool1State(AgentState):\n",
    "    \"\"\"Shared state for Tool 1 graph.\"\"\"\n",
    "\n",
    "    # Input data\n",
    "    entities: list[str]\n",
    "    scope_out: str\n",
    "    candidates: list[dict]\n",
    "\n",
    "    # Processing results\n",
    "    raw_mappings: list[dict] | None = None\n",
    "    filtered_mappings: list[dict] | None = None\n",
    "\n",
    "    # Output paths\n",
    "    output_json_path: str | None = None\n",
    "    output_artifact_path: str | None = None\n",
    "\n",
    "print(\"âœ… Schemas & state defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1f4c8e",
   "metadata": {},
   "source": [
    "## 2. Node 1: Load Data\n",
    "\n",
    "Load Tool 0 JSON (entities, scope_out) + BS export JSON (candidates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c48758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Load node defined\n"
     ]
    }
   ],
   "source": [
    "def load_node(state: Tool1State) -> dict:\n",
    "    \"\"\"Load Tool 0 output and BS export.\"\"\"\n",
    "    print(\"ðŸ“‚ Node 1: Loading data...\")\n",
    "\n",
    "    # Load Tool 0 JSON\n",
    "    tool0_path = Path.cwd().parent / 'data' / 'tool0_samples' / '2025-10-31T01:14:27.960789.json'\n",
    "    with open(tool0_path, 'r', encoding='utf-8') as f:\n",
    "        tool0_data = json.load(f)\n",
    "\n",
    "    entities = tool0_data.get('entities', [])\n",
    "    scope_out = tool0_data.get('scope_out', '')\n",
    "\n",
    "    print(f\"   âœ… Loaded {len(entities)} entities from Tool 0\")\n",
    "    print(f\"   âœ… Scope out: {scope_out[:100]}...\")\n",
    "\n",
    "    # Load BS export JSON (pre-filtered externally: flattened, deduped, BS-only)\n",
    "    bs_path = Path.cwd().parent / 'docs_langgraph' / 'BA-BS_Datamarts_metadata.json'\n",
    "    with open(bs_path, 'r', encoding='utf-8') as f:\n",
    "        bs_data = json.load(f)\n",
    "\n",
    "    # Flatten array-of-arrays structure\n",
    "    if isinstance(bs_data, list) and len(bs_data) > 0 and isinstance(bs_data[0], list):\n",
    "        candidates_flat = bs_data[0]  # Extract inner array\n",
    "    else:\n",
    "        candidates_flat = bs_data\n",
    "\n",
    "    # Filter to BS-only (dm_bs_* prefix) - FIX: use 'displayName' not 'name'\n",
    "    candidates = [\n",
    "        c for c in candidates_flat\n",
    "        if isinstance(c, dict) and c.get('displayName', '').startswith('dm_bs_')\n",
    "    ]\n",
    "\n",
    "    print(f\"   âœ… Loaded {len(candidates)} BS candidates\")\n",
    "    if candidates:\n",
    "        print(f\"   ðŸ“‹ Candidates:\")\n",
    "        for c in candidates:\n",
    "            print(f\"      - {c.get('displayName')}: {c.get('description', 'N/A')[:60]}...\")\n",
    "\n",
    "    return {\n",
    "        'entities': entities,\n",
    "        'scope_out': scope_out,\n",
    "        'candidates': candidates\n",
    "    }\n",
    "\n",
    "print(\"âœ… Load node defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f69f7f",
   "metadata": {},
   "source": [
    "## 3. Node 2: Prepare Candidates (LLM Ranking)\n",
    "\n",
    "**LLM-based prefiltering:** Rank candidates by relevance for entities (showcase multiple LLM nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52685258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prepare node (LLM ranking) defined\n"
     ]
    }
   ],
   "source": [
    "# Pydantic schema for candidate ranking\n",
    "class CandidateRank(BaseModel):\n",
    "    \"\"\"Single candidate with relevance score.\"\"\"\n",
    "\n",
    "    candidate_id: str = Field(description=\"Candidate identifier\")\n",
    "    relevance_score: float = Field(\n",
    "        description=\"Relevance score 0.0-1.0\",\n",
    "        ge=0.0,\n",
    "        le=1.0\n",
    "    )\n",
    "    reason: str = Field(description=\"Why this candidate is relevant\")\n",
    "\n",
    "\n",
    "class CandidateRanking(BaseModel):\n",
    "    \"\"\"Ranked list of candidates.\"\"\"\n",
    "\n",
    "    ranked_candidates: list[CandidateRank] = Field(\n",
    "        description=\"Candidates ranked by relevance\"\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_node(state: Tool1State) -> dict:\n",
    "    \"\"\"LLM ranks candidates by relevance for entities.\"\"\"\n",
    "    print(\"ðŸ”§ Node 2: LLM ranking candidates...\")\n",
    "\n",
    "    entities = state['entities']\n",
    "    candidates = state['candidates']\n",
    "\n",
    "    print(f\"   Input: {len(entities)} entities, {len(candidates)} candidates\")\n",
    "\n",
    "    # Prepare candidate summaries for LLM\n",
    "    candidate_summaries = []\n",
    "    for c in candidates:\n",
    "        desc = c.get('description', '')\n",
    "        candidate_summaries.append({\n",
    "            'id': c.get('displayName', 'unknown'),\n",
    "            'name': c.get('fullName', c.get('displayName', 'unknown')),\n",
    "            'description': desc[:200] + '...' if len(desc) > 200 else desc\n",
    "        })\n",
    "\n",
    "    # Create lightweight ranking agent\n",
    "    ranking_agent = create_agent(\n",
    "        model=\"openai:gpt-5-mini\",\n",
    "        response_format=ToolStrategy(CandidateRanking),\n",
    "        tools=[],\n",
    "        system_prompt=\"\"\"You are a data relevance analyzer.\n",
    "Rank database candidates by relevance for the given business entities.\n",
    "\n",
    "Consider:\n",
    "- Semantic similarity between entity names and candidate names/descriptions\n",
    "- Domain relevance (e.g., \"suppliers\" â†’ purchasing schemas)\n",
    "- Czech/English terminology overlap\n",
    "\n",
    "Return relevance scores (0.0-1.0) and reasons.\"\"\"\n",
    "    )\n",
    "\n",
    "    # Prepare ranking request\n",
    "    ranking_request = f\"\"\"Rank these candidates by relevance for the business entities:\n",
    "\n",
    "**Business Entities:**\n",
    "{json.dumps(entities, indent=2, ensure_ascii=False)}\n",
    "\n",
    "**Available Candidates:**\n",
    "{json.dumps(candidate_summaries, indent=2, ensure_ascii=False)}\n",
    "\n",
    "Return ranked candidates with relevance scores.\"\"\"\n",
    "\n",
    "    # Invoke ranking agent\n",
    "    result = ranking_agent.invoke({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": ranking_request}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Extract structured response\n",
    "    structured_response = result.get('structured_response')\n",
    "    if not structured_response:\n",
    "        raise ValueError(\"No structured response from ranking agent\")\n",
    "\n",
    "    # Convert to dict\n",
    "    ranking_data = (\n",
    "        structured_response.model_dump()\n",
    "        if hasattr(structured_response, 'model_dump')\n",
    "        else structured_response.dict()\n",
    "    )\n",
    "\n",
    "    ranked_list = ranking_data.get('ranked_candidates', [])\n",
    "\n",
    "    # Take top N (or all if fewer) - for demo, take all with score > 0.3\n",
    "    relevant_candidates = [\n",
    "        r for r in ranked_list\n",
    "        if r['relevance_score'] > 0.3\n",
    "    ]\n",
    "\n",
    "    # Match back to full candidate objects\n",
    "    ranked_candidate_ids = [r['candidate_id'] for r in relevant_candidates]\n",
    "    prepared_candidates = [\n",
    "        {\n",
    "            'id': c.get('displayName', 'unknown'),\n",
    "            'name': c.get('fullName', c.get('displayName', 'unknown')),\n",
    "            'description': c.get('description', '')[:200] + '...'\n",
    "                if len(c.get('description', '')) > 200\n",
    "                else c.get('description', ''),\n",
    "            'relevance_score': next(\n",
    "                (r['relevance_score'] for r in relevant_candidates if r['candidate_id'] == c.get('displayName')),\n",
    "                0.0\n",
    "            )\n",
    "        }\n",
    "        for c in candidates\n",
    "        if c.get('displayName') in ranked_candidate_ids\n",
    "    ]\n",
    "\n",
    "    print(f\"   âœ… Ranked {len(ranked_list)} candidates\")\n",
    "    print(f\"   âœ… Selected {len(prepared_candidates)} relevant (score > 0.3)\")\n",
    "\n",
    "    return {\n",
    "        'candidates': prepared_candidates\n",
    "    }\n",
    "\n",
    "print(\"âœ… Prepare node (LLM ranking) defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4b7e56",
   "metadata": {},
   "source": [
    "## 4. Node 3: LLM Mapping (Agent with Middleware)\n",
    "\n",
    "Use LangGraph agent with:\n",
    "- Structured output (ToolStrategy)\n",
    "- Dynamic prompt middleware (inject scope_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07530031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mapping node defined\n"
     ]
    }
   ],
   "source": [
    "def mapping_node(state: Tool1State) -> dict:\n",
    "    \"\"\"Map entities to candidates using LLM agent.\"\"\"\n",
    "    print(\"ðŸ¤– Node 3: LLM mapping with agent...\")\n",
    "\n",
    "    entities = state['entities']\n",
    "    candidates = state['candidates']\n",
    "    scope_out = state['scope_out']\n",
    "\n",
    "    # Dynamic prompt middleware (inject scope_out)\n",
    "    @dynamic_prompt\n",
    "    def scope_aware_prompt(request) -> str:\n",
    "        return f\"\"\"You are an entity mapper. Map business entities to database candidates using fuzzy matching.\n",
    "\n",
    "Consider:\n",
    "- Synonyms (e.g., \"dodavatelÃ©\" = \"suppliers\")\n",
    "- Czech/English variants\n",
    "- Partial name matches\n",
    "- Description context\n",
    "\n",
    "IMPORTANT: Avoid candidates related to these excluded topics:\n",
    "{scope_out}\n",
    "\n",
    "Return confidence scores (0.0-1.0) and rationale for each mapping.\"\"\"\n",
    "\n",
    "    # Create agent with structured output\n",
    "    agent = create_agent(\n",
    "        model=\"openai:gpt-5-mini\",\n",
    "        response_format=ToolStrategy(MappingSuggestions),\n",
    "        tools=[],  # No tools needed for single-shot mapping\n",
    "        middleware=[scope_aware_prompt]\n",
    "    )\n",
    "\n",
    "    # Prepare user message\n",
    "    user_message = f\"\"\"Map these entities to the best matching candidates:\n",
    "\n",
    "**Entities to map:**\n",
    "{json.dumps(entities, indent=2, ensure_ascii=False)}\n",
    "\n",
    "**Available candidates:**\n",
    "{json.dumps(candidates, indent=2, ensure_ascii=False)}\n",
    "\n",
    "Return mappings with confidence scores and rationale.\"\"\"\n",
    "\n",
    "    # Invoke agent\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Extract structured response\n",
    "    structured_response = result.get('structured_response')\n",
    "    if not structured_response:\n",
    "        raise ValueError(\"No structured response from agent\")\n",
    "\n",
    "    # Convert to dict\n",
    "    mappings_data = (\n",
    "        structured_response.model_dump()\n",
    "        if hasattr(structured_response, 'model_dump')\n",
    "        else structured_response.dict()\n",
    "    )\n",
    "\n",
    "    raw_mappings = mappings_data.get('mappings', [])\n",
    "\n",
    "    print(f\"   âœ… Generated {len(raw_mappings)} mappings\")\n",
    "\n",
    "    return {\n",
    "        'raw_mappings': raw_mappings\n",
    "    }\n",
    "\n",
    "print(\"âœ… Mapping node defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db7c88",
   "metadata": {},
   "source": [
    "## 5. Node 4: Filter Blacklist\n",
    "\n",
    "Apply deterministic scope_out blacklist filter (historical, logs, security terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc6b2fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filter node defined\n"
     ]
    }
   ],
   "source": [
    "def filter_node(state: Tool1State) -> dict:\n",
    "    \"\"\"Filter mappings using scope_out blacklist.\"\"\"\n",
    "    print(\"ðŸ” Node 4: Applying blacklist filter...\")\n",
    "\n",
    "    raw_mappings = state['raw_mappings']\n",
    "    scope_out = state['scope_out'].lower()\n",
    "\n",
    "    # Define blacklist keywords\n",
    "    blacklist = ['historical', 'logs', 'security', 'archive', 'audit']\n",
    "\n",
    "    # Also extract keywords from scope_out\n",
    "    scope_keywords = [\n",
    "        word.strip().lower()\n",
    "        for word in scope_out.split()\n",
    "        if len(word.strip()) > 3\n",
    "    ]\n",
    "\n",
    "    all_blacklist = set(blacklist + scope_keywords)\n",
    "\n",
    "    # Filter mappings\n",
    "    filtered = []\n",
    "    for mapping in raw_mappings:\n",
    "        candidate_name = mapping.get('candidate_name', '').lower()\n",
    "        candidate_id = mapping.get('candidate_id', '').lower()\n",
    "\n",
    "        # Check if any blacklist term appears\n",
    "        is_blacklisted = any(\n",
    "            term in candidate_name or term in candidate_id\n",
    "            for term in all_blacklist\n",
    "        )\n",
    "\n",
    "        if not is_blacklisted:\n",
    "            filtered.append(mapping)\n",
    "\n",
    "    removed_count = len(raw_mappings) - len(filtered)\n",
    "    print(f\"   âœ… Filtered: {len(filtered)} kept, {removed_count} removed\")\n",
    "\n",
    "    return {\n",
    "        'filtered_mappings': filtered\n",
    "    }\n",
    "\n",
    "print(\"âœ… Filter node defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea3af54",
   "metadata": {},
   "source": [
    "## 6. Node 5: Save Results\n",
    "\n",
    "Save filtered_dataset.json + ingest summary to artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43d7284f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Save node defined\n"
     ]
    }
   ],
   "source": [
    "def save_node(state: Tool1State) -> dict:\n",
    "    \"\"\"Save filtered dataset and artifacts.\"\"\"\n",
    "    print(\"ðŸ’¾ Node 5: Saving results...\")\n",
    "\n",
    "    entities = state['entities']\n",
    "    filtered_mappings = state['filtered_mappings']\n",
    "    scope_out = state['scope_out']\n",
    "\n",
    "    timestamp = datetime.now().isoformat()\n",
    "\n",
    "    # Prepare filtered dataset\n",
    "    filtered_dataset = {\n",
    "        'timestamp': timestamp,\n",
    "        'business_context': {\n",
    "            'entities': entities,\n",
    "            'scope_out': scope_out\n",
    "        },\n",
    "        'mappings': filtered_mappings,\n",
    "        'stats': {\n",
    "            'total_entities': len(entities),\n",
    "            'mapped_entities': len(filtered_mappings),\n",
    "            'avg_confidence': (\n",
    "                sum(m['confidence'] for m in filtered_mappings) / len(filtered_mappings)\n",
    "                if filtered_mappings else 0.0\n",
    "            )\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save to data/tool1/\n",
    "    output_dir = Path.cwd().parent / 'data' / 'tool1'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    json_path = output_dir / 'filtered_dataset.json'\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(filtered_dataset, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"   âœ… Dataset saved: {json_path}\")\n",
    "\n",
    "    # Save artifacts summary\n",
    "    artifacts_dir = Path.cwd().parent / 'scrum' / 'artifacts'\n",
    "    artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    artifact_path = artifacts_dir / f\"{timestamp.split('T')[0]}_tool1-ingest-summary.json\"\n",
    "    with open(artifact_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(filtered_dataset['stats'], f, indent=2)\n",
    "\n",
    "    print(f\"   âœ… Artifact saved: {artifact_path}\")\n",
    "\n",
    "    return {\n",
    "        'output_json_path': str(json_path),\n",
    "        'output_artifact_path': str(artifact_path)\n",
    "    }\n",
    "\n",
    "print(\"âœ… Save node defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b90b3",
   "metadata": {},
   "source": [
    "## 7. Build LangGraph\n",
    "\n",
    "Connect nodes: Load â†’ Prepare â†’ Mapping â†’ Filter â†’ Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c77f25bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph compiled\n",
      "\n",
      "ðŸ“Š Graph structure:\n",
      "   START â†’ load â†’ prepare â†’ mapping â†’ filter â†’ save â†’ END\n"
     ]
    }
   ],
   "source": [
    "# Build state graph\n",
    "builder = StateGraph(Tool1State)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node('load', load_node)\n",
    "builder.add_node('prepare', prepare_node)\n",
    "builder.add_node('mapping', mapping_node)\n",
    "builder.add_node('filter', filter_node)\n",
    "builder.add_node('save', save_node)\n",
    "\n",
    "# Define edges\n",
    "builder.add_edge(START, 'load')\n",
    "builder.add_edge('load', 'prepare')\n",
    "builder.add_edge('prepare', 'mapping')\n",
    "builder.add_edge('mapping', 'filter')\n",
    "builder.add_edge('filter', 'save')\n",
    "builder.add_edge('save', END)\n",
    "\n",
    "# Compile graph\n",
    "graph = builder.compile()\n",
    "\n",
    "print(\"âœ… LangGraph compiled\")\n",
    "print(\"\\nðŸ“Š Graph structure:\")\n",
    "print(\"   START â†’ load â†’ prepare â†’ mapping â†’ filter â†’ save â†’ END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eae163",
   "metadata": {},
   "source": [
    "## 8. Execute Graph\n",
    "\n",
    "Run the complete pipeline and stream progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a66d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Executing Tool 1 pipeline...\n",
      "\n",
      "============================================================\n",
      "ðŸ“‚ Node 1: Loading data...\n",
      "   âœ… Loaded 4 entities from Tool 0\n",
      "   âœ… Scope out: HR data o zamÄ›stnancÃ­ch; FinanÄnÃ­ forecasting a budgetovÃ¡nÃ­; Real-time monitoring dodÃ¡vek; Integrace...\n",
      "   âœ… Loaded 1 BS candidates\n",
      "   ðŸ“‹ Candidates:\n",
      "      - dm_bs_purchase: BS (Production Purchasing) Reporting Data Mart...\n",
      "ðŸ”§ Node 2: LLM ranking candidates...\n",
      "   Input: 4 entities, 1 candidates\n",
      "   âœ… Ranked 1 candidates\n",
      "   âœ… Selected 1 relevant (score > 0.3)\n",
      "ðŸ¤– Node 3: LLM mapping with agent...\n",
      "   âœ… Generated 4 mappings\n",
      "ðŸ” Node 4: Applying blacklist filter...\n",
      "   âœ… Filtered: 4 kept, 0 removed\n",
      "ðŸ’¾ Node 5: Saving results...\n",
      "   âœ… Dataset saved: /Users/marekminarovic/archi-agent/data/tool1/filtered_dataset.json\n",
      "   âœ… Artifact saved: /Users/marekminarovic/archi-agent/scrum/artifacts/2025-10-31_tool1-ingest-summary.json\n",
      "============================================================\n",
      "\n",
      "âœ… Pipeline complete!\n",
      "\n",
      "ðŸ“Š Final Results:\n",
      "   Entities processed: 4\n",
      "   Mappings generated: 4\n",
      "   Mappings after filter: 4\n",
      "   Output JSON: /Users/marekminarovic/archi-agent/data/tool1/filtered_dataset.json\n",
      "   Artifact: /Users/marekminarovic/archi-agent/scrum/artifacts/2025-10-31_tool1-ingest-summary.json\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸš€ Executing Tool 1 pipeline...\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Execute graph\n",
    "final_state = graph.invoke({})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nâœ… Pipeline complete!\")\n",
    "print(f\"\\nðŸ“Š Final Results:\")\n",
    "print(f\"   Entities processed: {len(final_state.get('entities', []))}\")\n",
    "print(f\"   Mappings generated: {len(final_state.get('raw_mappings', []))}\")\n",
    "print(f\"   Mappings after filter: {len(final_state.get('filtered_mappings', []))}\")\n",
    "print(f\"   Output JSON: {final_state.get('output_json_path')}\")\n",
    "print(f\"   Artifact: {final_state.get('output_artifact_path')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d009dab8",
   "metadata": {},
   "source": [
    "## 9. Display Results\n",
    "\n",
    "Show filtered mappings with confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eac2e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Filtered Entity Mappings:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "1. Suppliers (dodavatelÃ©) â†’ Systems>dap_gold_prod>dm_bs_purchase\n",
      "   ID: dm_bs_purchase\n",
      "   Confidence: 0.92\n",
      "   Rationale: Strong fuzzy match: 'Suppliers' (Czech: 'dodavatelÃ©') is a core master dimension used by purchasing data marts. The candidate is a Purchasing Reporting Data Mart ('BS (Production Purchasing) Reporting Data Mart'), so it likely contains vendor/supplier master and supplier-related transaction attributes. No conflict with excluded topics.\n",
      "\n",
      "2. Purchase Orders (nÃ¡kupnÃ­ objednÃ¡vky) â†’ Systems>dap_gold_prod>dm_bs_purchase\n",
      "   ID: dm_bs_purchase\n",
      "   Confidence: 0.98\n",
      "   Rationale: Very high confidence: the candidate is explicitly a 'Purchasing' reporting data mart, so purchase orders (nÃ¡kupnÃ­ objednÃ¡vky) are a primary object in this domain. The name and description match directly. Excluded topics do not apply.\n",
      "\n",
      "3. Products (produkty) â†’ Systems>dap_gold_prod>dm_bs_purchase\n",
      "   ID: dm_bs_purchase\n",
      "   Confidence: 0.80\n",
      "   Rationale: Moderate confidence: purchasing marts commonly include product/item identifiers (SKUs) for PO line items and matching. The Czech term 'produkty' aligns with 'products' and likely maps to item/product attributes in this DM, though full product master details might live in a separate product data mart.\n",
      "\n",
      "4. Delivery Performance (vÃ½konnost dodÃ¡vek) â†’ Systems>dap_gold_prod>dm_bs_purchase\n",
      "   ID: dm_bs_purchase\n",
      "   Confidence: 0.65\n",
      "   Rationale: Lower confidence: delivery performance (vÃ½konnost dodÃ¡vek) can be derived from purchasing data (POs, receipts, delivery dates) and may be partially present in a Purchasing DM. However, delivery performance metrics are also often maintained in logistics/transportation or dedicated supply chain marts, so mapping is plausible but not certain. Also ensure this isn't interpreted as real-time monitoring (which is excluded) â€” this mapping is for reporting/historical metrics only.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ðŸ“ˆ Statistics:\n",
      "   Average confidence: 0.84\n",
      "   High confidence (â‰¥0.8): 3/4\n"
     ]
    }
   ],
   "source": [
    "# Display filtered mappings\n",
    "filtered_mappings = final_state.get('filtered_mappings', [])\n",
    "\n",
    "print(\"ðŸ“‹ Filtered Entity Mappings:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, mapping in enumerate(filtered_mappings, 1):\n",
    "    print(f\"\\n{i}. {mapping['entity']} â†’ {mapping['candidate_name']}\")\n",
    "    print(f\"   ID: {mapping['candidate_id']}\")\n",
    "    print(f\"   Confidence: {mapping['confidence']:.2f}\")\n",
    "    print(f\"   Rationale: {mapping['rationale']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Calculate stats\n",
    "if filtered_mappings:\n",
    "    avg_confidence = sum(m['confidence'] for m in filtered_mappings) / len(filtered_mappings)\n",
    "    high_confidence = sum(1 for m in filtered_mappings if m['confidence'] >= 0.8)\n",
    "\n",
    "    print(f\"\\nðŸ“ˆ Statistics:\")\n",
    "    print(f\"   Average confidence: {avg_confidence:.2f}\")\n",
    "    print(f\"   High confidence (â‰¥0.8): {high_confidence}/{len(filtered_mappings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e75e4",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "âœ… **LangGraph Features Demonstrated:**\n",
    "- [x] Agent with discrete nodes (load, prepare, mapping, filter, save)\n",
    "- [x] **Multiple LLM nodes:**\n",
    "  - **Prepare Node:** LLM ranking (relevance scores)\n",
    "  - **Mapping Node:** LLM matching (confidence + rationale)\n",
    "- [x] Shared state (Tool1State) across all nodes\n",
    "- [x] Structured output via ToolStrategy in 2 contexts (CandidateRanking, MappingSuggestions)\n",
    "- [x] Dynamic prompt middleware (inject scope_out blacklist)\n",
    "- [x] Streaming progress between nodes\n",
    "- [x] \"Each node does one thing well\" principle\n",
    "\n",
    "**Model:** openai:gpt-5-mini (consistent, no dynamic routing)\n",
    "\n",
    "**2-Stage LLM Approach:**\n",
    "1. **Prepare Node:** Ranks candidates by relevance (lightweight prefilter)\n",
    "2. **Mapping Node:** Detailed entity-to-candidate matching with confidence\n",
    "\n",
    "**Outputs:**\n",
    "- `data/tool1/filtered_dataset.json` - Complete dataset with mappings\n",
    "- `scrum/artifacts/YYYY-MM-DD_tool1-ingest-summary.json` - Statistics summary\n",
    "\n",
    "**Why This Architecture:**\n",
    "- Showcases LangGraph's multi-node intelligence pattern\n",
    "- Testuje rÅ¯znÃ© structured output schemas (ranking vs mapping)\n",
    "- Demonstrates separation of concerns (relevance vs matching)\n",
    "- Not necessary for 2 candidates, but excellent LangGraph demonstration\n",
    "\n",
    "**Next Steps:**\n",
    "1. Run compliance checker: `python3 .claude/skills/langchain/compliance-checker/check.py --file notebooks/tool1_ingest_demo.ipynb`\n",
    "2. Update story: `scrum/backlog/tool1-data-ingest.md` (`skill_created: true`)\n",
    "3. Test with different Tool 0 outputs\n",
    "4. Evaluate ranking quality vs direct mapping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
