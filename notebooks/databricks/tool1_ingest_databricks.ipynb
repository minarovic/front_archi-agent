{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a27e9430",
   "metadata": {},
   "source": [
    "# Tool 1 - Entity to Candidate Mapper (Parallel Multi-Agent Pattern)\n",
    "\n",
    "**Status:** ‚úÖ Ready for Databricks | **LLM Cost:** ~$0.003 per run | **Performance:** ~10s\n",
    "\n",
    "**Pattern:** 2 Pydantic AI agents running in parallel via `asyncio.gather`\n",
    "\n",
    "**Showcase:** Parallel multi-agent execution - both agents run simultaneously, results merged with consistency validation.\n",
    "\n",
    "**Key Features:**\n",
    "- 2 specialized agents: `ranking_agent` (top 10 candidates) + `mapping_agent` (1:1 entity mappings)\n",
    "- Parallel execution with `asyncio.gather` (both agents run simultaneously)\n",
    "- Consistency check validates overlap between ranked and mapped candidates (target: >70%)\n",
    "- Expected performance: ~10s for parallel execution\n",
    "\n",
    "**TODO:**\n",
    "- [ ] Add retry logic for LLM failures (timeout, rate limit)\n",
    "- [ ] Cache ranking results for repeated entity sets\n",
    "- [ ] Test with 20+ entities (current test: 5-10)\n",
    "- [ ] Add metadata quality score (completeness, freshness)\n",
    "\n",
    "**IDEA:**\n",
    "- Consider hybrid: embedding similarity for initial filtering + LLM for final ranking\n",
    "- Add configurable top-N parameter (currently hardcoded to 10)\n",
    "- Export consistency report as separate artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b187655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install pydantic-ai>=0.0.49 pydantic>=2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart Python kernel to use new packages\n",
    "dbutils.library.restartPython()  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42758af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5145844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Azure OpenAI from Databricks secrets\n",
    "AZURE_ENDPOINT = dbutils.secrets.get(scope=\"mcop\", key=\"azure-openai-endpoint\").strip()  # type: ignore\n",
    "AZURE_API_KEY = dbutils.secrets.get(scope=\"mcop\", key=\"azure-openai-api-key\").strip()  # type: ignore\n",
    "DEPLOYMENT_NAME = dbutils.secrets.get(scope=\"mcop\", key=\"azure-openai-deployment-name\").strip()  # type: ignore\n",
    "\n",
    "# Clean endpoint (remove /openai/v1/ if present - Pydantic AI will handle routing)\n",
    "azure_endpoint_clean = AZURE_ENDPOINT.replace(\"/openai/v1/\", \"\").replace(\"/openai/v1\", \"\").rstrip(\"/\")\n",
    "\n",
    "# Set environment variables for Pydantic AI (Azure OpenAI compatible)\n",
    "os.environ[\"OPENAI_BASE_URL\"] = f\"{azure_endpoint_clean}/openai/deployments/{DEPLOYMENT_NAME}\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = AZURE_API_KEY\n",
    "\n",
    "MODEL_NAME = f\"openai:{DEPLOYMENT_NAME}\"\n",
    "print(f\"‚úÖ Configured model: {MODEL_NAME}\")\n",
    "print(f\"   Base URL: {os.environ['OPENAI_BASE_URL']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb2aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# PYDANTIC SCHEMAS - 4 modely pro 2 agenty\n",
    "# ==========================================\n",
    "# Tool 1 pou≈æ√≠v√° 2 specializovan√© LLM agenty, kter√© bƒõ≈æ√≠ PARALELNƒö:\n",
    "# - ranking_agent ‚Üí vrac√≠ CandidateRanking (top 10 kandid√°t≈Ø)\n",
    "# - mapping_agent ‚Üí vrac√≠ MappingSuggestions (1:1 mapov√°n√≠ entity‚Üíkandid√°t)\n",
    "#\n",
    "# Ka≈æd√Ω agent pot≈ôebuje vlastn√≠ output schema.\n",
    "\n",
    "class CandidateRank(BaseModel):\n",
    "    \"\"\"Jeden kandid√°t z rankingu (1 polo≈æka v top 10).\n",
    "\n",
    "    Co obsahuje:\n",
    "    - entity_id: ID z metadata katalogu (nap≈ô. UUID z Collibra)\n",
    "    - rank: Po≈ôad√≠ v ≈æeb≈ô√≠ƒçku (1 = nejlep≈°√≠, 10 = nejhor≈°√≠)\n",
    "    - relevance_score: Sk√≥re relevance 0.0-1.0 (vy≈°≈°√≠ = relevantnƒõj≈°√≠)\n",
    "    - justification: Textov√© zd≈Øvodnƒõn√≠, proƒç je kandid√°t relevantn√≠\n",
    "\n",
    "    P≈ô√≠klad:\n",
    "    {\n",
    "      \"entity_id\": \"c9c9fdf4-27ed-479d-b03b-f8ccec7a9f91\",\n",
    "      \"rank\": 1,\n",
    "      \"relevance_score\": 0.95,\n",
    "      \"justification\": \"Perfect match: dimv_supplier table in dm_ba_purchase schema\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    entity_id: str = Field(description=\"Entity ID\")\n",
    "    rank: int = Field(description=\"Rank position (1=best)\")\n",
    "    relevance_score: float = Field(description=\"Relevance 0-1\")\n",
    "    justification: str = Field(description=\"Why this candidate is relevant\")\n",
    "\n",
    "class CandidateRanking(BaseModel):\n",
    "    \"\"\"V√Ωstup z ranking_agent - top 10 kandid√°t≈Ø se≈ôazen√Ωch podle relevance.\n",
    "\n",
    "    Toto je ROOT MODEL pro ranking_agent (result_type=CandidateRanking).\n",
    "    LLM MUS√ç vr√°tit objekt s polem 'top_candidates' obsahuj√≠c√≠m array 10 polo≈æek.\n",
    "\n",
    "    Jak to funguje:\n",
    "    1. ranking_agent dostane business entity + seznam ALL kandid√°t≈Ø z metadatu\n",
    "    2. LLM ohodnot√≠ kandid√°ty podle s√©mantick√© podobnosti, kvality, metadat\n",
    "    3. Vr√°t√≠ top 10 s po≈ôad√≠m, sk√≥re a zd≈Øvodnƒõn√≠m\n",
    "    \"\"\"\n",
    "    top_candidates: list[CandidateRank] = Field(description=\"Top 10 candidates\")\n",
    "\n",
    "class EntityMapping(BaseModel):\n",
    "    \"\"\"Jeden mapping: business entita ‚Üí best matching candidate.\n",
    "\n",
    "    Co obsahuje:\n",
    "    - entity_name: Jm√©no business entity z Tool 0 (nap≈ô. \"Supplier Master\")\n",
    "    - matched_candidate_id: ID kandid√°ta z metadatu (UUID)\n",
    "    - confidence: Jistota mapov√°n√≠ 0.0-1.0 (>0.7 = high confidence)\n",
    "    - reasoning: Textov√© vysvƒõtlen√≠, proƒç byl vybr√°n tento kandid√°t\n",
    "\n",
    "    P≈ô√≠klad:\n",
    "    {\n",
    "      \"entity_name\": \"Supplier Master\",\n",
    "      \"matched_candidate_id\": \"c9c9fdf4-27ed-479d-b03b-f8ccec7a9f91\",\n",
    "      \"confidence\": 0.92,\n",
    "      \"reasoning\": \"Name match + description alignment + quality metadata present\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    entity_name: str = Field(description=\"Business entity name\")\n",
    "    matched_candidate_id: str = Field(description=\"Mapped candidate ID\")\n",
    "    confidence: float = Field(description=\"Mapping confidence 0-1\")\n",
    "    reasoning: str = Field(description=\"Mapping rationale\")\n",
    "\n",
    "class MappingSuggestions(BaseModel):\n",
    "    \"\"\"V√Ωstup z mapping_agent - 1:1 mapov√°n√≠ v≈°ech entit.\n",
    "\n",
    "    Toto je ROOT MODEL pro mapping_agent (result_type=MappingSuggestions).\n",
    "    LLM MUS√ç vr√°tit objekt s polem 'mappings' - array EntityMapping objekt≈Ø.\n",
    "\n",
    "    Jak to funguje:\n",
    "    1. mapping_agent dostane stejn√Ω input jako ranking_agent\n",
    "    2. LLM pro KA≈ΩDOU business entitu vybere JEDNOHO nejlep≈°√≠ho kandid√°ta\n",
    "    3. Vr√°t√≠ array s N mapov√°n√≠mi (N = poƒçet business entit)\n",
    "\n",
    "    Rozd√≠l oproti ranking:\n",
    "    - Ranking: \"Jak√© jsou top 10 kandid√°ti celkovƒõ?\"\n",
    "    - Mapping: \"Pro entitu X, kter√Ω je nejlep≈°√≠ kandid√°t a proƒç?\"\n",
    "    \"\"\"\n",
    "    mappings: list[EntityMapping] = Field(description=\"Entity mappings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# PYDANTIC AI AGENTS - 2 specializovan√© LLM agenty\n",
    "# ==========================================\n",
    "# Pydantic AI pattern:\n",
    "# Agent(model_name, result_type=Schema, system_prompt=\"...\")\n",
    "#\n",
    "# Co to dƒõl√°:\n",
    "# - Vytvo≈ô√≠ LLM agenta s p≈ôedem definovan√Ωm output sch√©matem\n",
    "# - result_type ≈ô√≠k√°: \"LLM MUS√ç vr√°tit data podle tohoto Pydantic modelu\"\n",
    "# - Pydantic AI automaticky:\n",
    "#   1. P≈ôid√° schema do LLM promptu (JSON Schema format)\n",
    "#   2. Zavol√° LLM s function calling / JSON mode\n",
    "#   3. Validuje response pomoc√≠ Pydantic\n",
    "#   4. Vr√°t√≠ type-safe Pydantic objekt (ne raw JSON string)\n",
    "\n",
    "# ==========================================\n",
    "# AGENT 1: ranking_agent\n",
    "# ==========================================\n",
    "# √öƒçel: Ohodnotit v≈°echny kandid√°ty a vr√°tit top 10\n",
    "# Input: business_entities + technical_metadata\n",
    "# Output: CandidateRanking (top 10 s rank, score, justification)\n",
    "#\n",
    "# System prompt vysvƒõtluje:\n",
    "# - Co m√° agent dƒõlat (rank candidates)\n",
    "# - Jak√° krit√©ria pou≈æ√≠t (semantic similarity, data quality, metadata presence)\n",
    "# - Jak form√°tovat output (structured ranking)\n",
    "ranking_agent = Agent(\n",
    "    MODEL_NAME,                      # \"openai:test-gpt-5-mini\" (Pydantic AI format)\n",
    "    result_type=CandidateRanking,    # LLM MUS√ç vr√°tit CandidateRanking object\n",
    "    system_prompt=\"\"\"You are a data catalog expert.\n",
    "\n",
    "Rank candidates by relevance to business entities:\n",
    "- Consider semantic similarity (name, description)\n",
    "- Evaluate data quality signals (completeness, freshness)\n",
    "- Prioritize candidates with metadata (owner, lineage, tags)\n",
    "- Top 10 most relevant candidates\n",
    "\n",
    "Return structured ranking with scores and justifications.\"\"\"\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# AGENT 2: mapping_agent\n",
    "# ==========================================\n",
    "# √öƒçel: Pro ka≈ædou entitu naj√≠t 1 nejlep≈°√≠ kandid√°t\n",
    "# Input: business_entities + technical_metadata (STEJN√ù jako ranking_agent)\n",
    "# Output: MappingSuggestions (N mappings, 1 per entity)\n",
    "#\n",
    "# Rozd√≠l oproti ranking_agent:\n",
    "# - Ranking: \"Top 10 candidates overall\" (aggregovan√Ω pohled)\n",
    "# - Mapping: \"Best match PER entity\" (detailn√≠ 1:1 mapov√°n√≠)\n",
    "#\n",
    "# System prompt specifikuje:\n",
    "# - 1:1 mapping (one entity ‚Üí one candidate)\n",
    "# - High confidence preferred (>0.7)\n",
    "# - Clear reasoning required\n",
    "mapping_agent = Agent(\n",
    "    MODEL_NAME,\n",
    "    result_type=MappingSuggestions,  # LLM MUS√ç vr√°tit MappingSuggestions object\n",
    "    system_prompt=\"\"\"You are a metadata mapping specialist.\n",
    "\n",
    "Map each business entity to the BEST matching candidate:\n",
    "- 1:1 mapping (one entity ‚Üí one candidate)\n",
    "- High confidence mappings (>0.7) preferred\n",
    "- Consider semantic alignment and context\n",
    "- Provide clear reasoning for each mapping\n",
    "\n",
    "Return structured mappings with confidence scores.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Ranking and mapping agents created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# PARALELN√ç SPU≈†TƒöN√ç 2 AGENT≈Æ - asyncio.gather()\n",
    "# ==========================================\n",
    "# Proƒç async pattern:\n",
    "# - Oba agenti dostanou STEJN√ù input (entities + metadata)\n",
    "# - Maj√≠ r≈Øzn√© √∫koly (ranking vs mapping)\n",
    "# - M≈Ø≈æou bƒõ≈æet PARALELNƒö ‚Üí ≈°et≈ô√≠ ƒças\n",
    "# - asyncio.gather() poƒçk√° na oba v√Ωsledky souƒçasnƒõ\n",
    "#\n",
    "# Klasick√Ω sequential:\n",
    "# result1 = ranking_agent.run()   # ‚è±Ô∏è 5s\n",
    "# result2 = mapping_agent.run()   # ‚è±Ô∏è 5s\n",
    "# Total: 10s\n",
    "#\n",
    "# Paralel with asyncio.gather():\n",
    "# results = asyncio.gather(ranking_agent.run(), mapping_agent.run())\n",
    "# Total: ~5s (oba bƒõ≈æ√≠ souƒçasnƒõ)\n",
    "\n",
    "async def map_entities_to_candidates(\n",
    "    business_entities: list[dict],     # Z Tool 0 (BusinessRequest.entities)\n",
    "    technical_metadata: list[dict]     # Z katalogu (Collibra/Unity Catalog)\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Namapuje business entity na technick√© kandid√°ty pomoc√≠ 2 LLM agent≈Ø.\n",
    "\n",
    "    Args:\n",
    "        business_entities: Seznam entit z business po≈æadavku\n",
    "            Form√°t: [{\"name\": \"Customer\", \"description\": \"...\", \"attributes\": [...]}, ...]\n",
    "\n",
    "        technical_metadata: Seznam technick√Ωch kandid√°t≈Ø z katalogu\n",
    "            Form√°t: [{\"name\": \"dim_customer\", \"schema\": \"...\", \"description\": \"...\", ...}, ...]\n",
    "\n",
    "    Returns:\n",
    "        dict s kl√≠ƒçi:\n",
    "        - \"ranking\": Top 10 candidates (CandidateRanking)\n",
    "        - \"mapping\": 1:1 entity‚Üícandidate mappings (MappingSuggestions)\n",
    "        - \"consistency\": Overlap analysis (kolik mapping kandid√°t≈Ø je v top 10)\n",
    "\n",
    "    Pydantic AI workflow:\n",
    "        1. P≈ôiprav input prompt (entities + metadata JSON)\n",
    "        2. Spus≈• OBA agenty paralelnƒõ (asyncio.gather)\n",
    "        3. ƒåekej na v√Ωsledky (result.data = Pydantic object)\n",
    "        4. Validuj konzistenci (mapping by mƒõl preferovat top 10 kandid√°ty)\n",
    "        5. Vra≈• kombinovan√© v√Ωsledky\n",
    "    \"\"\"\n",
    "\n",
    "    # ==========================================\n",
    "    # KROK 1: P≈ôiprav input data pro LLM\n",
    "    # ==========================================\n",
    "    # Pydantic AI automaticky p≈ôid√° schema do promptu,\n",
    "    # ale mus√≠me dodat business kontext (entities + metadata)\n",
    "    user_prompt = f\"\"\"\n",
    "Business Entities (from requirement):\n",
    "{json.dumps(business_entities, indent=2, ensure_ascii=False)}\n",
    "\n",
    "Technical Metadata Candidates (from catalog):\n",
    "{json.dumps(technical_metadata, indent=2, ensure_ascii=False)}\n",
    "\"\"\"\n",
    "\n",
    "    # ==========================================\n",
    "    # KROK 2: Spus≈• OBA agenty PARALELNƒö\n",
    "    # ==========================================\n",
    "    # asyncio.gather() pattern:\n",
    "    # - Vezme N async funkc√≠/coroutines\n",
    "    # - Spust√≠ v≈°echny souƒçasnƒõ (non-blocking)\n",
    "    # - Vr√°t√≠ tuple s v√Ωsledky ve stejn√©m po≈ôad√≠\n",
    "    #\n",
    "    # agent.run_sync() vs agent.run():\n",
    "    # - run_sync() = synchronn√≠ verze (pro non-async k√≥d)\n",
    "    # - run() = async verze (pro asyncio.gather)\n",
    "    #\n",
    "    # result object struktura:\n",
    "    # - result.data = Pydantic object (CandidateRanking / MappingSuggestions)\n",
    "    # - result.cost = API cost tracking (optional)\n",
    "    # - result.timestamp = run timestamp\n",
    "\n",
    "    ranking_result, mapping_result = await asyncio.gather(\n",
    "        ranking_agent.run(user_prompt),      # Async coroutine 1\n",
    "        mapping_agent.run(user_prompt)       # Async coroutine 2\n",
    "    )\n",
    "\n",
    "    # ==========================================\n",
    "    # KROK 3: Extrahuj Pydantic objekty z result\n",
    "    # ==========================================\n",
    "    # result.data je u≈æ VALIDOVAN√ù Pydantic object\n",
    "    # (ne raw JSON string - to Pydantic AI u≈æ zpracoval)\n",
    "\n",
    "    ranking_data: CandidateRanking = ranking_result.data\n",
    "    # Type: CandidateRanking(root=[CandidateRank(...), ...])\n",
    "    # Access: ranking_data.root[0].entity_id, ranking_data.root[0].rank, ...\n",
    "\n",
    "    mapping_data: MappingSuggestions = mapping_result.data\n",
    "    # Type: MappingSuggestions(root=[EntityMapping(...), ...])\n",
    "    # Access: mapping_data.root[0].entity_name, mapping_data.root[0].matched_candidate_id, ...\n",
    "\n",
    "    # ==========================================\n",
    "    # KROK 4: Validuj konzistenci (optional check)\n",
    "    # ==========================================\n",
    "    # Dobr√Ω mapping by mƒõl preferovat kandid√°ty z top 10 rankingu.\n",
    "    # Pokud mapping vrac√≠ √∫plnƒõ jin√© kandid√°ty, m≈Ø≈æe to signalizovat:\n",
    "    # - Konfliktn√≠ krit√©ria mezi agenty\n",
    "    # - Nedostatek kvalitn√≠ch kandid√°t≈Ø\n",
    "    # - Pot≈ôebu review ƒçlovƒõkem\n",
    "\n",
    "    top_10_ids = {candidate.entity_id for candidate in ranking_data.root}\n",
    "    mapped_ids = {mapping.matched_candidate_id for mapping in mapping_data.root}\n",
    "    overlap = top_10_ids.intersection(mapped_ids)\n",
    "\n",
    "    consistency_note = (\n",
    "        f\"Mapping consistency: {len(overlap)}/{len(mapped_ids)} mapped candidates \"\n",
    "        f\"are in top 10 ranking.\"\n",
    "    )\n",
    "\n",
    "    if len(overlap) < len(mapped_ids) * 0.5:  # M√©nƒõ ne≈æ 50% overlap\n",
    "        consistency_note += \" ‚ö†Ô∏è Low overlap - consider manual review.\"\n",
    "\n",
    "    # ==========================================\n",
    "    # KROK 5: Vra≈• kombinovan√© v√Ωsledky\n",
    "    # ==========================================\n",
    "    return {\n",
    "        \"ranking\": ranking_data.model_dump(),      # Convert Pydantic ‚Üí dict\n",
    "        \"mapping\": mapping_data.model_dump(),      # Convert Pydantic ‚Üí dict\n",
    "        \"consistency\": {\n",
    "            \"overlap_count\": len(overlap),\n",
    "            \"total_mappings\": len(mapped_ids),\n",
    "            \"overlap_percentage\": len(overlap) / len(mapped_ids) if mapped_ids else 0,\n",
    "            \"note\": consistency_note\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Entity mapping function defined (async with parallel agents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data from DBFS\n",
    "tool0_path = \"/dbfs/FileStore/mcop/tool0_samples/sample_business_request.json\"\n",
    "metadata_path = \"/dbfs/FileStore/mcop/metadata/BA-BS_Datamarts_metadata.json\"\n",
    "\n",
    "with open(tool0_path, \"r\") as f:\n",
    "    tool0_data = json.load(f)\n",
    "\n",
    "with open(metadata_path, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "entities = tool0_data.get(\"entities\", [])\n",
    "print(f\"‚úÖ Loaded {len(entities)} entities from Tool 0\")\n",
    "print(f\"‚úÖ Loaded {len(metadata)} metadata items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run parallel mapping\n",
    "result = await map_entities_to_candidates(entities, metadata)\n",
    "\n",
    "print(f\"\\n‚úÖ Parallel mapping complete\")\n",
    "print(f\"   Rankings: {len(result['rankings'])}\")\n",
    "print(f\"   Mappings: {len(result['mappings'])}\")\n",
    "print(f\"   Consistency: {result['consistency_check']['consistency_ratio']:.1%} ({result['consistency_check']['status']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to DBFS\n",
    "output_path = \"/dbfs/FileStore/mcop/tool1/filtered_dataset.json\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Results saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f523f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample results with consistency check\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PARALLEL MULTI-AGENT MAPPING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüèÜ Top 5 Ranked Candidates:\")\n",
    "for candidate in result['rankings'][:5]:\n",
    "    print(f\"   {candidate['rank']}. {candidate['entity_id']} (score: {candidate['relevance_score']:.2f})\")\n",
    "    print(f\"      ‚Üí {candidate['justification'][:80]}...\")\n",
    "\n",
    "print(f\"\\nüîó Sample Mappings (top 5):\")\n",
    "for mapping in result['mappings'][:5]:\n",
    "    print(f\"   {mapping['entity_name']} ‚Üí {mapping['matched_candidate_id']}\")\n",
    "    print(f\"      Confidence: {mapping['confidence']:.1%}\")\n",
    "    print(f\"      Reasoning: {mapping['reasoning'][:80]}...\")\n",
    "\n",
    "print(f\"\\n‚úÖ Consistency Check:\")\n",
    "print(f\"   Overlap: {result['consistency_check']['overlap_count']} / {result['consistency_check']['total_mappings']}\")\n",
    "print(f\"   Ratio: {result['consistency_check']['consistency_ratio']:.1%}\")\n",
    "print(f\"   Status: {result['consistency_check']['status']}\")\n",
    "print(f\"   Expected: >70% for good quality (ranking and mapping agree)\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
