{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7002d45f",
   "metadata": {},
   "source": [
    "# Tool 3 - Quality Validator (Hybrid Pattern)\n",
    "\n",
    "**Status:** ‚úÖ Ready for Databricks | **LLM Cost:** $0 (deterministic) or ~$0.002 (hybrid) | **Performance:** <1s or ~10s\n",
    "\n",
    "**Pattern:** Deterministic coverage checks + optional LLM enhancement\n",
    "\n",
    "**Showcase:** Hybrid validation - fast deterministic metrics + smart LLM risk assessment (configurable).\n",
    "\n",
    "**Key Features:**\n",
    "- Hybrid async function with configurable LLM fallback (`use_llm_enhancement=True/False`)\n",
    "- Deterministic coverage metrics: description, owner, source (always runs, <1s)\n",
    "- Optional LLM enhancement: risk level (LOW/MEDIUM/HIGH/CRITICAL), text quality, P0/P1/P2 recommendations\n",
    "- Anomaly detection: orphan entities, missing owners, suspicious patterns\n",
    "- Two modes: `hybrid` (default) or `deterministic_only`\n",
    "\n",
    "**TODO:**\n",
    "- [ ] Add lineage coverage metric (upstream/downstream sources)\n",
    "- [ ] Validate recommendation priority distribution (not all P0)\n",
    "- [ ] Test with low-quality metadata (0% coverage scenarios)\n",
    "- [ ] Add trend analysis (quality over time)\n",
    "\n",
    "**IDEA:**\n",
    "- Cache LLM enhancement results for unchanged structures (avoid re-analysis)\n",
    "- Add custom quality rules engine (user-defined thresholds)\n",
    "- Export recommendations as actionable Jira/GitHub issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dcd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install pydantic-ai>=0.0.49 pydantic>=2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450028f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart Python kernel to use new packages\n",
    "dbutils.library.restartPython()  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fffc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Azure OpenAI from Databricks secrets\n",
    "AZURE_ENDPOINT = dbutils.secrets.get(scope=\"mcop\", key=\"azure-openai-endpoint\")  # type: ignore\n",
    "AZURE_API_KEY = dbutils.secrets.get(scope=\"mcop\", key=\"azure-openai-api-key\")  # type: ignore\n",
    "DEPLOYMENT_NAME = dbutils.secrets.get(scope=\"mcop\", key=\"azure-openai-deployment-name\")  # type: ignore\n",
    "\n",
    "# Set environment variables for Pydantic AI\n",
    "os.environ[\"OPENAI_BASE_URL\"] = AZURE_ENDPOINT\n",
    "os.environ[\"OPENAI_API_KEY\"] = AZURE_API_KEY\n",
    "\n",
    "MODEL_NAME = f\"openai:{DEPLOYMENT_NAME}\"\n",
    "print(f\"‚úÖ Configured model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a53541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic schemas\n",
    "class Recommendation(BaseModel):\n",
    "    \"\"\"Quality improvement recommendation.\"\"\"\n",
    "    priority: str = Field(description=\"P0 (critical), P1 (high), P2 (medium)\")\n",
    "    category: str = Field(description=\"Category: coverage, consistency, naming, security\")\n",
    "    message: str = Field(description=\"Actionable recommendation text\")\n",
    "\n",
    "class AnomalyNote(BaseModel):\n",
    "    \"\"\"Data quality anomaly.\"\"\"\n",
    "    entity: str = Field(description=\"Entity or table name with anomaly\")\n",
    "    anomaly_type: str = Field(description=\"Type: orphan_entity, missing_owner, suspicious_pattern\")\n",
    "    severity: str = Field(description=\"Severity: high, medium, low\")\n",
    "    details: str = Field(description=\"Anomaly details\")\n",
    "\n",
    "class LLMEnhancement(BaseModel):\n",
    "    \"\"\"LLM-enhanced quality assessment.\"\"\"\n",
    "    risk_level: str = Field(description=\"Overall risk: LOW, MEDIUM, HIGH, CRITICAL\")\n",
    "    text_quality_score: float = Field(description=\"Text quality 0-1\")\n",
    "    recommendations: list[Recommendation] = Field(description=\"P0/P1/P2 recommendations\")\n",
    "    anomalies: list[AnomalyNote] = Field(default_factory=list, description=\"Detected anomalies\")\n",
    "    summary: str = Field(description=\"Executive summary\")\n",
    "\n",
    "class CoverageMetrics(BaseModel):\n",
    "    \"\"\"Deterministic coverage metrics.\"\"\"\n",
    "    description_coverage: float = Field(description=\"Fraction of entities with descriptions\")\n",
    "    owner_coverage: float = Field(description=\"Fraction of entities with owners\")\n",
    "    source_coverage: float = Field(description=\"Fraction of entities with sources\")\n",
    "    total_entities: int = Field(description=\"Total entities evaluated\")\n",
    "    timestamp: str = Field(description=\"ISO 8601 timestamp\")\n",
    "\n",
    "class QualityReport(BaseModel):\n",
    "    \"\"\"Complete quality validation report.\"\"\"\n",
    "    coverage: CoverageMetrics\n",
    "    llm_enhancement: LLMEnhancement | None = None\n",
    "    execution_time_seconds: float\n",
    "    mode: str = Field(description=\"hybrid or deterministic_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186641ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM enhancement agent\n",
    "enhancement_agent = Agent(\n",
    "    MODEL_NAME,\n",
    "    result_type=LLMEnhancement,\n",
    "    system_prompt=\"\"\"You are a metadata quality expert.\n",
    "\n",
    "Analyze the provided structure and assess:\n",
    "1. Risk level (LOW/MEDIUM/HIGH/CRITICAL) based on coverage gaps\n",
    "2. Text quality score (0-1) for descriptions and documentation\n",
    "3. Prioritized recommendations (P0=critical, P1=high, P2=medium)\n",
    "4. Data quality anomalies (orphan entities, missing owners, suspicious patterns)\n",
    "5. Executive summary for stakeholders\n",
    "\n",
    "Be specific and actionable.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Enhancement agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e4f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def validate_quality(structure: dict, use_llm_enhancement: bool = True) -> QualityReport:\n",
    "    \"\"\"Hybrid quality validation: deterministic coverage + optional LLM enhancement.\n",
    "\n",
    "    Args:\n",
    "        structure: Tool 2 structural classification output\n",
    "        use_llm_enhancement: If True, runs LLM analysis (~10s). If False, only coverage (<1s).\n",
    "\n",
    "    Returns:\n",
    "        QualityReport with coverage metrics and optional LLM assessment\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # Step 1: Deterministic coverage (always runs, <1s)\n",
    "    all_entities = structure.get(\"facts\", []) + structure.get(\"dimensions\", [])\n",
    "    total = len(all_entities)\n",
    "\n",
    "    description_count = sum(1 for e in all_entities if e.get(\"description\"))\n",
    "    owner_count = sum(1 for e in all_entities if e.get(\"owner\"))\n",
    "    source_count = sum(1 for e in all_entities if e.get(\"source\"))\n",
    "\n",
    "    coverage = CoverageMetrics(\n",
    "        description_coverage=description_count / total if total > 0 else 0.0,\n",
    "        owner_coverage=owner_count / total if total > 0 else 0.0,\n",
    "        source_coverage=source_count / total if total > 0 else 0.0,\n",
    "        total_entities=total,\n",
    "        timestamp=datetime.now().isoformat()\n",
    "    )\n",
    "\n",
    "    # Step 2: Optional LLM enhancement (~10s)\n",
    "    llm_result = None\n",
    "    if use_llm_enhancement:\n",
    "        prompt = f\"\"\"Analyze this metadata structure:\n",
    "\n",
    "Coverage Metrics:\n",
    "- Description coverage: {coverage.description_coverage:.1%}\n",
    "- Owner coverage: {coverage.owner_coverage:.1%}\n",
    "- Source coverage: {coverage.source_coverage:.1%}\n",
    "\n",
    "Structure:\n",
    "{json.dumps(structure, indent=2)}\n",
    "\n",
    "Provide risk assessment, quality score, recommendations (P0/P1/P2), anomalies, and summary.\"\"\"\n",
    "\n",
    "        result = await enhancement_agent.run(prompt)\n",
    "        llm_result = result.data\n",
    "\n",
    "    execution_time = (datetime.now() - start_time).total_seconds()\n",
    "    mode = \"hybrid\" if use_llm_enhancement else \"deterministic_only\"\n",
    "\n",
    "    return QualityReport(\n",
    "        coverage=coverage,\n",
    "        llm_enhancement=llm_result,\n",
    "        execution_time_seconds=execution_time,\n",
    "        mode=mode\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Hybrid validation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tool 2 structure from DBFS\n",
    "structure_path = \"/dbfs/FileStore/mcop/tool2/structure.json\"\n",
    "\n",
    "with open(structure_path, \"r\") as f:\n",
    "    structure = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded structure from: {structure_path}\")\n",
    "print(f\"   Facts: {len(structure.get('facts', []))}\")\n",
    "print(f\"   Dimensions: {len(structure.get('dimensions', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae15116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run hybrid validation (deterministic + LLM)\n",
    "report = await validate_quality(structure, use_llm_enhancement=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Validation complete ({report.mode} mode)\")\n",
    "print(f\"   Execution time: {report.execution_time_seconds:.2f}s\")\n",
    "print(f\"\\nüìä Coverage Metrics:\")\n",
    "print(f\"   Description: {report.coverage.description_coverage:.1%}\")\n",
    "print(f\"   Owner: {report.coverage.owner_coverage:.1%}\")\n",
    "print(f\"   Source: {report.coverage.source_coverage:.1%}\")\n",
    "\n",
    "if report.llm_enhancement:\n",
    "    print(f\"\\nü§ñ LLM Enhancement:\")\n",
    "    print(f\"   Risk Level: {report.llm_enhancement.risk_level}\")\n",
    "    print(f\"   Text Quality: {report.llm_enhancement.text_quality_score:.2f}\")\n",
    "    print(f\"   Recommendations: {len(report.llm_enhancement.recommendations)}\")\n",
    "    print(f\"   Anomalies: {len(report.llm_enhancement.anomalies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quality report to DBFS\n",
    "output_path = \"/dbfs/FileStore/mcop/tool3/quality_report.json\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(report.model_dump(), f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Quality report saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e46e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUALITY VALIDATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìà Coverage Summary:\")\n",
    "print(f\"   Total entities: {report.coverage.total_entities}\")\n",
    "print(f\"   Description coverage: {report.coverage.description_coverage:.1%}\")\n",
    "print(f\"   Owner coverage: {report.coverage.owner_coverage:.1%}\")\n",
    "print(f\"   Source coverage: {report.coverage.source_coverage:.1%}\")\n",
    "\n",
    "if report.llm_enhancement:\n",
    "    print(f\"\\nüîç Risk Assessment:\")\n",
    "    print(f\"   Risk Level: {report.llm_enhancement.risk_level}\")\n",
    "    print(f\"   Text Quality: {report.llm_enhancement.text_quality_score:.2f}\")\n",
    "\n",
    "    print(f\"\\nüí° Recommendations ({len(report.llm_enhancement.recommendations)}):\")\n",
    "    for rec in report.llm_enhancement.recommendations[:5]:  # Top 5\n",
    "        print(f\"   [{rec.priority}] {rec.category}: {rec.message}\")\n",
    "\n",
    "    print(f\"\\n‚ö†Ô∏è  Anomalies ({len(report.llm_enhancement.anomalies)}):\")\n",
    "    for anomaly in report.llm_enhancement.anomalies[:3]:  # Top 3\n",
    "        print(f\"   [{anomaly.severity.upper()}] {anomaly.anomaly_type}: {anomaly.details}\")\n",
    "\n",
    "    print(f\"\\nüìù Executive Summary:\")\n",
    "    print(f\"   {report.llm_enhancement.summary}\")\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Execution: {report.execution_time_seconds:.2f}s ({report.mode} mode)\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
