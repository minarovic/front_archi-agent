{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7002d45f",
   "metadata": {},
   "source": [
    "# Tool 3 - Quality Validator (Hybrid Pattern)\n",
    "\n",
    "**Status:** ‚úÖ Ready for Databricks | **LLM Cost:** $0 (deterministic) or ~$0.002 (hybrid) | **Performance:** <1s or ~10s\n",
    "\n",
    "**Pattern:** Deterministic coverage checks + optional LLM enhancement\n",
    "\n",
    "**Showcase:** Hybrid validation - fast deterministic metrics + smart LLM risk assessment (configurable).\n",
    "\n",
    "**Key Features:**\n",
    "- Hybrid async function with configurable LLM fallback (`use_llm_enhancement=True/False`)\n",
    "- Deterministic coverage metrics: description, owner, source (always runs, <1s)\n",
    "- Optional LLM enhancement: risk level (LOW/MEDIUM/HIGH/CRITICAL), text quality, P0/P1/P2 recommendations\n",
    "- Anomaly detection: orphan entities, missing owners, suspicious patterns\n",
    "- Two modes: `hybrid` (default) or `deterministic_only`\n",
    "\n",
    "**TODO:**\n",
    "- [ ] Add lineage coverage metric (upstream/downstream sources)\n",
    "- [ ] Validate recommendation priority distribution (not all P0)\n",
    "- [ ] Test with low-quality metadata (0% coverage scenarios)\n",
    "- [ ] Add trend analysis (quality over time)\n",
    "\n",
    "**IDEA:**\n",
    "- Cache LLM enhancement results for unchanged structures (avoid re-analysis)\n",
    "- Add custom quality rules engine (user-defined thresholds)\n",
    "- Export recommendations as actionable Jira/GitHub issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dcd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install pydantic-ai>=0.0.49 pydantic>=2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450028f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart Python kernel to use new packages\n",
    "dbutils.library.restartPython()  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fffc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Azure OpenAI from Databricks secrets\n",
    "AZURE_ENDPOINT = dbutils.secrets.get(scope=\"mcop\", key=\"azure-openai-endpoint\").strip()  # type: ignore\n",
    "AZURE_API_KEY = dbutils.secrets.get(scope=\"mcop\", key=\"azure-openai-api-key\").strip()  # type: ignore\n",
    "DEPLOYMENT_NAME = dbutils.secrets.get(scope=\"mcop\", key=\"azure-openai-deployment-name\").strip()  # type: ignore\n",
    "\n",
    "# Clean endpoint (remove /openai/v1/ if present - Pydantic AI will handle routing)\n",
    "azure_endpoint_clean = AZURE_ENDPOINT.replace(\"/openai/v1/\", \"\").replace(\"/openai/v1\", \"\").rstrip(\"/\")\n",
    "\n",
    "# Set environment variables for Pydantic AI (Azure OpenAI compatible)\n",
    "os.environ[\"OPENAI_BASE_URL\"] = f\"{azure_endpoint_clean}/openai/deployments/{DEPLOYMENT_NAME}\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = AZURE_API_KEY\n",
    "\n",
    "MODEL_NAME = f\"openai:{DEPLOYMENT_NAME}\"\n",
    "print(f\"‚úÖ Configured model: {MODEL_NAME}\")\n",
    "print(f\"   Base URL: {os.environ['OPENAI_BASE_URL']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a53541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# PYDANTIC SCHEMAS - HYBRID QUALITY VALIDATION\n",
    "# ==========================================\n",
    "# Tool 3 √∫ƒçel: Validovat metadata kvalitu pomoc√≠ HYBRID patternu\n",
    "# - DETERMINISTIC ƒç√°st: Coverage metrics (v≈ædy bƒõ≈æ√≠, <1s)\n",
    "# - LLM ENHANCEMENT ƒç√°st: S√©mantick√° anal√Ωza (optional, ~10s)\n",
    "#\n",
    "# Proƒç hybrid:\n",
    "# - Deterministick√© metriky = rychl√©, spolehliv√©, konzistentn√≠\n",
    "# - LLM enhancement = kontextov√©, s√©mantick√©, human-like reasoning\n",
    "# - Use case: Produkce = deterministic only, Review = hybrid\n",
    "\n",
    "# ==========================================\n",
    "# SCHEMA 1: Recommendation (doporuƒçen√≠ pro zlep≈°en√≠)\n",
    "# ==========================================\n",
    "# Co je Recommendation:\n",
    "# - Actionable improvement suggestion z LLM\n",
    "# - Prioritizov√°no (P0/P1/P2) pro task management\n",
    "# - Kategorizov√°no (coverage/consistency/naming/security)\n",
    "#\n",
    "# P≈ô√≠klady:\n",
    "# - P0: \"Critical: 5 fact tables missing owners\" (mus√≠ se vy≈ôe≈°it ASAP)\n",
    "# - P1: \"High: 30% tables lack descriptions\" (d≈Øle≈æit√©, ale ne blocker)\n",
    "# - P2: \"Medium: Consider standardizing naming convention\" (nice-to-have)\n",
    "class Recommendation(BaseModel):\n",
    "    \"\"\"Quality improvement recommendation (z LLM enhancement).\n",
    "\n",
    "    Pydantic pou≈æit√≠:\n",
    "    - priority: P0 (critical - blocker), P1 (high - important), P2 (medium - nice-to-have)\n",
    "    - category: Typ probl√©mu\n",
    "      * coverage: Chybƒõj√≠c√≠ metadata (description, owner, source)\n",
    "      * consistency: Nekonzistentn√≠ naming, formatting\n",
    "      * naming: Naming conventions violations\n",
    "      * security: Security concerns (PII exposure, access control)\n",
    "    - message: Actionable text (ne jen \"bad quality\", ale \"Add descriptions to 5 fact tables: ...\")\n",
    "    \"\"\"\n",
    "    priority: str = Field(description=\"P0 (critical), P1 (high), P2 (medium)\")\n",
    "    category: str = Field(description=\"Category: coverage, consistency, naming, security\")\n",
    "    message: str = Field(description=\"Actionable recommendation text\")\n",
    "\n",
    "# ==========================================\n",
    "# SCHEMA 2: AnomalyNote (datov√° anom√°lie)\n",
    "# ==========================================\n",
    "# Co je AnomalyNote:\n",
    "# - Detekovan√° data quality issue (z LLM anal√Ωzy)\n",
    "# - Suspicious patterns (orphan entities, missing owners, weird naming)\n",
    "# - Severity-based prioritization\n",
    "#\n",
    "# P≈ô√≠klady:\n",
    "# - \"Orphan entity: customer_backup table (no FK relationships, no owner)\"\n",
    "# - \"Missing owner: 3 dimension tables have NULL owner_id\"\n",
    "# - \"Suspicious pattern: tmp_data_2023 (temp table in production?)\"\n",
    "class AnomalyNote(BaseModel):\n",
    "    \"\"\"Data quality anomaly (detekovan√° z LLM anal√Ωzy).\n",
    "\n",
    "    Pydantic pou≈æit√≠:\n",
    "    - entity: Kter√° entita/tabulka m√° probl√©m\n",
    "    - anomaly_type: Typ anom√°lie\n",
    "      * orphan_entity: Entity bez vztah≈Ø (izolovan√° tabulka)\n",
    "      * missing_owner: Entity bez vlastn√≠ka (governance risk)\n",
    "      * suspicious_pattern: Weird naming/structure (tmp_, backup_, test_)\n",
    "    - severity: high (must fix), medium (should review), low (nice-to-know)\n",
    "    - details: Konkr√©tn√≠ popis (ne jen \"anomaly found\", ale \"Table has 0 FK, created 2y ago, no usage\")\n",
    "    \"\"\"\n",
    "    entity: str = Field(description=\"Entity or table name with anomaly\")\n",
    "    anomaly_type: str = Field(description=\"Type: orphan_entity, missing_owner, suspicious_pattern\")\n",
    "    severity: str = Field(description=\"Severity: high, medium, low\")\n",
    "    details: str = Field(description=\"Anomaly details\")\n",
    "\n",
    "# ==========================================\n",
    "# SCHEMA 3: LLMEnhancement (LLM s√©mantick√° anal√Ωza)\n",
    "# ==========================================\n",
    "# Co je LLMEnhancement:\n",
    "# - ROOT MODEL pro enhancement_agent (result_type)\n",
    "# - S√©mantick√° anal√Ωza nad deterministick√Ωmi metrikami\n",
    "# - Human-like reasoning (risk assessment, text quality, anomalies)\n",
    "#\n",
    "# Proƒç LLM:\n",
    "# - Risk level vy≈æaduje kontext (30% missing owners = HIGH or MEDIUM? Depends on entity criticality)\n",
    "# - Text quality scoring = s√©mantick√° anal√Ωza (nen√≠ jen \"is description present\", ale \"is it useful?\")\n",
    "# - Anomaly detection = pattern recognition (LLM um√≠ naj√≠t suspicious patterns)\n",
    "class LLMEnhancement(BaseModel):\n",
    "    \"\"\"LLM-enhanced quality assessment (optional, ~10s).\n",
    "\n",
    "    Pydantic pou≈æit√≠:\n",
    "    - risk_level: Aggregovan√Ω risk assessment\n",
    "      * CRITICAL: Major governance gaps (>50% missing owners, 0 descriptions)\n",
    "      * HIGH: Significant issues (20-50% coverage gaps)\n",
    "      * MEDIUM: Minor issues (5-20% gaps)\n",
    "      * LOW: Good quality (<5% gaps)\n",
    "    - text_quality_score: S√©mantick√° kvalita text≈Ø (0.0-1.0)\n",
    "      * 1.0 = v≈°echny descriptions jsou detailed, actionable, up-to-date\n",
    "      * 0.5 = descriptions jsou generic, outdated, nebo incomplete\n",
    "      * 0.0 = missing descriptions nebo complete gibberish\n",
    "    - recommendations: List[Recommendation] prioritizovan√Ωch akc√≠ (P0/P1/P2)\n",
    "    - anomalies: List[AnomalyNote] detekovan√Ωch weird patterns\n",
    "    - summary: Executive summary pro stakeholders (1-2 vƒõty)\n",
    "    \"\"\"\n",
    "    risk_level: str = Field(description=\"Overall risk: LOW, MEDIUM, HIGH, CRITICAL\")\n",
    "    text_quality_score: float = Field(description=\"Text quality 0-1\")\n",
    "    recommendations: list[Recommendation] = Field(description=\"P0/P1/P2 recommendations\")\n",
    "    anomalies: list[AnomalyNote] = Field(default_factory=list, description=\"Detected anomalies\")\n",
    "    summary: str = Field(description=\"Executive summary\")\n",
    "\n",
    "# ==========================================\n",
    "# SCHEMA 4: CoverageMetrics (deterministick√© metriky)\n",
    "# ==========================================\n",
    "# Co je CoverageMetrics:\n",
    "# - Rychl√© (<1s) coverage statistics\n",
    "# - Fraction-based (0.0-1.0) pro easy comparison\n",
    "# - V≈ΩDY bƒõ≈æ√≠ (i kdy≈æ LLM enhancement = False)\n",
    "#\n",
    "# Proƒç deterministick√©:\n",
    "# - Consistency: V≈ædy stejn√Ω v√Ωsledek pro stejn√Ω input\n",
    "# - Speed: <1s (no LLM call)\n",
    "# - Auditability: Clear calculation logic\n",
    "class CoverageMetrics(BaseModel):\n",
    "    \"\"\"Deterministic coverage metrics (V≈ΩDY bƒõ≈æ√≠, <1s).\n",
    "\n",
    "    Pydantic pou≈æit√≠:\n",
    "    - description_coverage: Kolik % entit m√° description\n",
    "      Calculation: entities_with_description / total_entities\n",
    "      Example: 8/10 tables have description ‚Üí 0.8\n",
    "    - owner_coverage: Kolik % entit m√° owner_id\n",
    "      Example: 5/10 tables have owner ‚Üí 0.5\n",
    "    - source_coverage: Kolik % entit m√° source system info\n",
    "      Example: 10/10 tables have source ‚Üí 1.0\n",
    "    - total_entities: Poƒçet evaluovan√Ωch entit (for context)\n",
    "    - timestamp: ISO 8601 timestamp (pro audit trail)\n",
    "    \"\"\"\n",
    "    description_coverage: float = Field(description=\"Fraction of entities with descriptions\")\n",
    "    owner_coverage: float = Field(description=\"Fraction of entities with owners\")\n",
    "    source_coverage: float = Field(description=\"Fraction of entities with sources\")\n",
    "    total_entities: int = Field(description=\"Total entities evaluated\")\n",
    "    timestamp: str = Field(description=\"ISO 8601 timestamp\")\n",
    "\n",
    "# ==========================================\n",
    "# SCHEMA 5: QualityReport (ROOT MODEL pro validate_quality function)\n",
    "# ==========================================\n",
    "# Co je QualityReport:\n",
    "# - Kompletn√≠ quality validation v√Ωsledek\n",
    "# - HYBRID: coverage (always) + llm_enhancement (optional)\n",
    "# - Execution time tracking (performance monitoring)\n",
    "#\n",
    "# Design pattern:\n",
    "# - coverage: CoverageMetrics (required, always present)\n",
    "# - llm_enhancement: LLMEnhancement | None (optional, depends on use_llm_enhancement flag)\n",
    "# - mode: \"hybrid\" or \"deterministic_only\" (pro audit trail)\n",
    "class QualityReport(BaseModel):\n",
    "    \"\"\"Complete quality validation report (hybrid pattern).\n",
    "\n",
    "    Pydantic pou≈æit√≠:\n",
    "    - coverage: CoverageMetrics (V≈ΩDY p≈ô√≠tomno, rychl√© metriky)\n",
    "    - llm_enhancement: LLMEnhancement | None (optional)\n",
    "      * None = use_llm_enhancement=False (produkce, rychl√Ω check)\n",
    "      * LLMEnhancement object = use_llm_enhancement=True (review, detailn√≠ anal√Ωza)\n",
    "    - execution_time_seconds: Performance tracking\n",
    "      * deterministic_only: <1s\n",
    "      * hybrid: ~10s (depends on LLM latency)\n",
    "    - mode: Which mode was used (pro audit trail)\n",
    "\n",
    "    Use cases:\n",
    "    - Produkce CI/CD: QualityReport(coverage=..., llm_enhancement=None, mode=\"deterministic_only\")\n",
    "      ‚Üí Rychl√Ω check, <1s, konzistentn√≠\n",
    "    - Manual review: QualityReport(coverage=..., llm_enhancement=..., mode=\"hybrid\")\n",
    "      ‚Üí Detailn√≠ anal√Ωza, ~10s, s√©mantick√© reasoning\n",
    "    \"\"\"\n",
    "    coverage: CoverageMetrics\n",
    "    llm_enhancement: LLMEnhancement | None = None\n",
    "    execution_time_seconds: float\n",
    "    mode: str = Field(description=\"hybrid or deterministic_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186641ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# PYDANTIC AI AGENT - enhancement_agent\n",
    "# ==========================================\n",
    "# √öƒçel: Optional LLM agent pro s√©mantickou kvalitu anal√Ωzu\n",
    "# Input: coverage metrics + structure JSON\n",
    "# Output: LLMEnhancement (risk_level, text_quality_score, recommendations, anomalies, summary)\n",
    "#\n",
    "# Proƒç OPTIONAL (ne always-on):\n",
    "# - Latency: ~10s per run (LLM call overhead)\n",
    "# - Cost: API charges per request\n",
    "# - Deterministic metrics ƒçasto staƒç√≠ (CI/CD pipelines)\n",
    "# - LLM enhancement = for deep reviews, manual audits\n",
    "#\n",
    "# Kdy pou≈æ√≠t LLM enhancement:\n",
    "# - ‚úÖ Manual metadata review sessions\n",
    "# - ‚úÖ Quarterly governance audits\n",
    "# - ‚úÖ Pre-production validation (before release)\n",
    "# - ‚ùå CI/CD automated checks (use deterministic only)\n",
    "# - ‚ùå Real-time dashboards (too slow)\n",
    "\n",
    "enhancement_agent = Agent(\n",
    "    MODEL_NAME,                          # \"openai:test-gpt-5-mini\"\n",
    "    result_type=LLMEnhancement,          # LLM MUS√ç vr√°tit LLMEnhancement object\n",
    "    system_prompt=\"\"\"You are a metadata quality expert.\n",
    "\n",
    "Analyze the provided structure and assess:\n",
    "1. Risk level (LOW/MEDIUM/HIGH/CRITICAL) based on coverage gaps\n",
    "2. Text quality score (0-1) for descriptions and documentation\n",
    "3. Prioritized recommendations (P0=critical, P1=high, P2=medium)\n",
    "4. Data quality anomalies (orphan entities, missing owners, suspicious patterns)\n",
    "5. Executive summary for stakeholders\n",
    "\n",
    "Be specific and actionable.\"\"\"\n",
    ")\n",
    "# System prompt strategie:\n",
    "# 1. Risk level: Kontextov√° anal√Ωza (30% missing owners = HIGH if critical entities)\n",
    "# 2. Text quality: S√©mantick√© scoring (ne jen \"present/absent\", ale \"useful/useless\")\n",
    "# 3. Recommendations: Prioritizace (P0 = must fix now, P1 = important, P2 = nice-to-have)\n",
    "# 4. Anomalies: Pattern recognition (orphan tables, suspicious naming, missing governance)\n",
    "# 5. Summary: Executive-friendly (non-technical language)\n",
    "#\n",
    "# LLM dostane:\n",
    "# - System prompt (v√Ω≈°e)\n",
    "# - User prompt (coverage metrics + structure JSON)\n",
    "# - JSON Schema pro LLMEnhancement (automaticky p≈ôid√°no Pydantic AI)\n",
    "#\n",
    "# LLM vr√°t√≠:\n",
    "# {\n",
    "#   \"risk_level\": \"HIGH\",\n",
    "#   \"text_quality_score\": 0.6,\n",
    "#   \"recommendations\": [\n",
    "#     {\"priority\": \"P0\", \"category\": \"coverage\", \"message\": \"Add owners to 5 fact tables\"},\n",
    "#     {\"priority\": \"P1\", \"category\": \"consistency\", \"message\": \"Standardize naming: use snake_case\"}\n",
    "#   ],\n",
    "#   \"anomalies\": [\n",
    "#     {\"entity\": \"tmp_data_2023\", \"anomaly_type\": \"suspicious_pattern\", \"severity\": \"medium\", \"details\": \"Temp table in prod?\"}\n",
    "#   ],\n",
    "#   \"summary\": \"Metadata quality has significant gaps (HIGH risk). Focus on owner coverage (50% missing).\"\n",
    "# }\n",
    "\n",
    "print(\"‚úÖ Enhancement agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e4f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# HYBRID VALIDATION FUNCTION - validate_quality()\n",
    "# ==========================================\n",
    "# Tool 3 HYBRID PATTERN:\n",
    "# - Step 1: DETERMINISTIC coverage metrics (V≈ΩDY bƒõ≈æ√≠, <1s)\n",
    "# - Step 2: OPTIONAL LLM enhancement (pokud use_llm_enhancement=True, ~10s)\n",
    "#\n",
    "# Proƒç hybrid design:\n",
    "# - Flexibility: M≈Ø≈æe≈° zvolit speed vs depth\n",
    "# - Cost optimization: LLM enhancement jen kdy≈æ pot≈ôebuje≈°\n",
    "# - Consistency: Deterministick√© metriky v≈ædy stejn√©\n",
    "# - Human-like reasoning: LLM enhancement pro context-aware analysis\n",
    "#\n",
    "# Use case matrix:\n",
    "# | Scenario                  | use_llm_enhancement | Execution time | Output                    |\n",
    "# |---------------------------|---------------------|----------------|---------------------------|\n",
    "# | CI/CD automated check     | False               | <1s            | Coverage metrics only     |\n",
    "# | Manual review session     | True                | ~10s           | Coverage + LLM insights   |\n",
    "# | Real-time dashboard       | False               | <1s            | Fast metrics              |\n",
    "# | Quarterly governance audit| True                | ~10s           | Deep analysis + actions   |\n",
    "\n",
    "async def validate_quality(structure: dict, use_llm_enhancement: bool = True) -> QualityReport:\n",
    "    \"\"\"Hybrid quality validation: deterministic coverage + optional LLM enhancement.\n",
    "\n",
    "    Args:\n",
    "        structure: Tool 2 structural classification output\n",
    "            Obsahuje: facts[], dimensions[], relationships[], metrics\n",
    "\n",
    "        use_llm_enhancement: If True, runs LLM analysis (~10s). If False, only coverage (<1s).\n",
    "            Default: True (comprehensive analysis)\n",
    "            Set False: For CI/CD, real-time checks, cost optimization\n",
    "\n",
    "    Returns:\n",
    "        QualityReport:\n",
    "        - coverage: CoverageMetrics (V≈ΩDY p≈ô√≠tomno)\n",
    "        - llm_enhancement: LLMEnhancement | None (depends on use_llm_enhancement)\n",
    "        - execution_time_seconds: Performance tracking\n",
    "        - mode: \"hybrid\" or \"deterministic_only\"\n",
    "\n",
    "    Workflow:\n",
    "        Step 1: Calculate deterministic coverage metrics (<1s)\n",
    "            - Count entities with description/owner/source\n",
    "            - Calculate fractions (0.0-1.0)\n",
    "            - Create CoverageMetrics object\n",
    "\n",
    "        Step 2: Optionally run LLM enhancement (~10s)\n",
    "            - IF use_llm_enhancement=True:\n",
    "                * Prepare prompt (coverage + structure)\n",
    "                * Call enhancement_agent\n",
    "                * Get LLMEnhancement object (risk, quality score, recommendations, anomalies)\n",
    "            - ELSE:\n",
    "                * Skip LLM call\n",
    "                * Set llm_enhancement=None\n",
    "\n",
    "        Step 3: Return QualityReport (combine deterministic + optional LLM)\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # ==========================================\n",
    "    # STEP 1: Deterministic coverage (V≈ΩDY bƒõ≈æ√≠)\n",
    "    # ==========================================\n",
    "    # Rychl√© metriky (<1s):\n",
    "    # - description_coverage = kolik % entit m√° description field\n",
    "    # - owner_coverage = kolik % entit m√° owner field\n",
    "    # - source_coverage = kolik % entit m√° source field\n",
    "    #\n",
    "    # Algorithm:\n",
    "    # 1. Merge facts + dimensions do all_entities list\n",
    "    # 2. Count entities where field is present (e.get(\"description\") returns truthy value)\n",
    "    # 3. Calculate fraction = count / total (0.0 if total=0 to avoid division by zero)\n",
    "\n",
    "    all_entities = structure.get(\"facts\", []) + structure.get(\"dimensions\", [])\n",
    "    total = len(all_entities)\n",
    "\n",
    "    description_count = sum(1 for e in all_entities if e.get(\"description\"))\n",
    "    owner_count = sum(1 for e in all_entities if e.get(\"owner\"))\n",
    "    source_count = sum(1 for e in all_entities if e.get(\"source\"))\n",
    "\n",
    "    coverage = CoverageMetrics(\n",
    "        description_coverage=description_count / total if total > 0 else 0.0,\n",
    "        owner_coverage=owner_count / total if total > 0 else 0.0,\n",
    "        source_coverage=source_count / total if total > 0 else 0.0,\n",
    "        total_entities=total,\n",
    "        timestamp=datetime.now().isoformat()\n",
    "    )\n",
    "    # Deterministick√Ω output:\n",
    "    # CoverageMetrics(\n",
    "    #   description_coverage=0.8,  # 8/10 entities have description\n",
    "    #   owner_coverage=0.5,        # 5/10 entities have owner\n",
    "    #   source_coverage=1.0,       # 10/10 entities have source\n",
    "    #   total_entities=10,\n",
    "    #   timestamp=\"2025-11-10T14:30:00Z\"\n",
    "    # )\n",
    "\n",
    "    # ==========================================\n",
    "    # STEP 2: Optional LLM enhancement\n",
    "    # ==========================================\n",
    "    # IF use_llm_enhancement=True:\n",
    "    #   - P≈ôiprav prompt s coverage metrics + structure JSON\n",
    "    #   - Zavolej enhancement_agent (LLM call, ~10s)\n",
    "    #   - Get LLMEnhancement object (risk_level, text_quality_score, recommendations, anomalies, summary)\n",
    "    # ELSE:\n",
    "    #   - Skip LLM call (save time & cost)\n",
    "    #   - Set llm_result=None\n",
    "\n",
    "    llm_result = None\n",
    "    if use_llm_enhancement:\n",
    "        prompt = f\"\"\"Analyze this metadata structure:\n",
    "\n",
    "Coverage Metrics:\n",
    "- Description coverage: {coverage.description_coverage:.1%}\n",
    "- Owner coverage: {coverage.owner_coverage:.1%}\n",
    "- Source coverage: {coverage.source_coverage:.1%}\n",
    "\n",
    "Structure:\n",
    "{json.dumps(structure, indent=2)}\n",
    "\n",
    "Provide risk assessment, quality score, recommendations (P0/P1/P2), anomalies, and summary.\"\"\"\n",
    "        # Prompt strategie:\n",
    "        # - Coverage metrics first (quick overview pro LLM)\n",
    "        # - Structure JSON second (full context)\n",
    "        # - Explicit ask for output fields (risk, quality, recommendations, anomalies, summary)\n",
    "\n",
    "        result = await enhancement_agent.run(prompt)\n",
    "        llm_result = result.data  # Type: LLMEnhancement\n",
    "        # LLM output example:\n",
    "        # LLMEnhancement(\n",
    "        #   risk_level=\"HIGH\",\n",
    "        #   text_quality_score=0.6,\n",
    "        #   recommendations=[\n",
    "        #     Recommendation(priority=\"P0\", category=\"coverage\", message=\"Add owners to 5 fact tables\"),\n",
    "        #     Recommendation(priority=\"P1\", category=\"consistency\", message=\"Standardize naming\")\n",
    "        #   ],\n",
    "        #   anomalies=[\n",
    "        #     AnomalyNote(entity=\"tmp_data\", anomaly_type=\"suspicious_pattern\", severity=\"medium\", details=\"Temp table in prod\")\n",
    "        #   ],\n",
    "        #   summary=\"HIGH risk due to 50% missing owners. Focus on governance gaps.\"\n",
    "        # )\n",
    "\n",
    "    # ==========================================\n",
    "    # STEP 3: Calculate execution time & mode\n",
    "    # ==========================================\n",
    "    execution_time = (datetime.now() - start_time).total_seconds()\n",
    "    mode = \"hybrid\" if use_llm_enhancement else \"deterministic_only\"\n",
    "    # Execution time examples:\n",
    "    # - deterministic_only: ~0.5s (just coverage calculation)\n",
    "    # - hybrid: ~10s (coverage + LLM call + validation)\n",
    "\n",
    "    # ==========================================\n",
    "    # STEP 4: Return QualityReport\n",
    "    # ==========================================\n",
    "    return QualityReport(\n",
    "        coverage=coverage,                      # CoverageMetrics (V≈ΩDY p≈ô√≠tomno)\n",
    "        llm_enhancement=llm_result,             # LLMEnhancement | None (depends on flag)\n",
    "        execution_time_seconds=execution_time,  # Performance tracking\n",
    "        mode=mode                               # \"hybrid\" or \"deterministic_only\"\n",
    "    )\n",
    "    # QualityReport usage:\n",
    "    # - report.coverage.description_coverage ‚Üí deterministick√° metrika\n",
    "    # - report.llm_enhancement.risk_level ‚Üí LLM assessment (if present)\n",
    "    # - report.llm_enhancement.recommendations ‚Üí actionable P0/P1/P2 items (if present)\n",
    "\n",
    "print(\"‚úÖ Hybrid validation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tool 2 structure from DBFS\n",
    "structure_path = \"/dbfs/FileStore/mcop/tool2/structure.json\"\n",
    "\n",
    "with open(structure_path, \"r\") as f:\n",
    "    structure = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded structure from: {structure_path}\")\n",
    "print(f\"   Facts: {len(structure.get('facts', []))}\")\n",
    "print(f\"   Dimensions: {len(structure.get('dimensions', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae15116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run hybrid validation (deterministic + LLM)\n",
    "report = await validate_quality(structure, use_llm_enhancement=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Validation complete ({report.mode} mode)\")\n",
    "print(f\"   Execution time: {report.execution_time_seconds:.2f}s\")\n",
    "print(f\"\\nüìä Coverage Metrics:\")\n",
    "print(f\"   Description: {report.coverage.description_coverage:.1%}\")\n",
    "print(f\"   Owner: {report.coverage.owner_coverage:.1%}\")\n",
    "print(f\"   Source: {report.coverage.source_coverage:.1%}\")\n",
    "\n",
    "if report.llm_enhancement:\n",
    "    print(f\"\\nü§ñ LLM Enhancement:\")\n",
    "    print(f\"   Risk Level: {report.llm_enhancement.risk_level}\")\n",
    "    print(f\"   Text Quality: {report.llm_enhancement.text_quality_score:.2f}\")\n",
    "    print(f\"   Recommendations: {len(report.llm_enhancement.recommendations)}\")\n",
    "    print(f\"   Anomalies: {len(report.llm_enhancement.anomalies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quality report to DBFS\n",
    "output_path = \"/dbfs/FileStore/mcop/tool3/quality_report.json\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(report.model_dump(), f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Quality report saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e46e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUALITY VALIDATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìà Coverage Summary:\")\n",
    "print(f\"   Total entities: {report.coverage.total_entities}\")\n",
    "print(f\"   Description coverage: {report.coverage.description_coverage:.1%}\")\n",
    "print(f\"   Owner coverage: {report.coverage.owner_coverage:.1%}\")\n",
    "print(f\"   Source coverage: {report.coverage.source_coverage:.1%}\")\n",
    "\n",
    "if report.llm_enhancement:\n",
    "    print(f\"\\nüîç Risk Assessment:\")\n",
    "    print(f\"   Risk Level: {report.llm_enhancement.risk_level}\")\n",
    "    print(f\"   Text Quality: {report.llm_enhancement.text_quality_score:.2f}\")\n",
    "\n",
    "    print(f\"\\nüí° Recommendations ({len(report.llm_enhancement.recommendations)}):\")\n",
    "    for rec in report.llm_enhancement.recommendations[:5]:  # Top 5\n",
    "        print(f\"   [{rec.priority}] {rec.category}: {rec.message}\")\n",
    "\n",
    "    print(f\"\\n‚ö†Ô∏è  Anomalies ({len(report.llm_enhancement.anomalies)}):\")\n",
    "    for anomaly in report.llm_enhancement.anomalies[:3]:  # Top 3\n",
    "        print(f\"   [{anomaly.severity.upper()}] {anomaly.anomaly_type}: {anomaly.details}\")\n",
    "\n",
    "    print(f\"\\nüìù Executive Summary:\")\n",
    "    print(f\"   {report.llm_enhancement.summary}\")\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Execution: {report.execution_time_seconds:.2f}s ({report.mode} mode)\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
